---------------- RUN 0  ------------------
Params for Embeddings:  {'q': 0.01}  with embedding type:  node2vec
Preprocess transition probs...
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.8s finished
Learning embedding vectors...
Learning embedding vectors done!
Embedded training set size: 1022640
Embedded test set size: 109978
Train test split summary: 
 Train X shape: (1022640, 128) Train y shape: (1022640,) 
 Test X shape: (109978, 128) Test y shape: (109978,)


Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 128)               16512     
_________________________________________________________________
activation (Activation)      (None, 128)               0         
_________________________________________________________________
dropout (Dropout)            (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 25)                3225      
_________________________________________________________________
activation_1 (Activation)    (None, 25)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 26        
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 19,763
Trainable params: 19,763
Non-trainable params: 0
_________________________________________________________________


Epoch 1/15
22371/22371 - 90s - loss: 0.2667 - mae: 0.3803 - val_loss: 0.1486 - val_mae: 0.2880
Epoch 2/15
22371/22371 - 66s - loss: 0.1496 - mae: 0.2876 - val_loss: 0.1263 - val_mae: 0.2608
Epoch 3/15
22371/22371 - 67s - loss: 0.1318 - mae: 0.2667 - val_loss: 0.1282 - val_mae: 0.2588
Epoch 4/15
22371/22371 - 74s - loss: 0.1237 - mae: 0.2562 - val_loss: 0.1282 - val_mae: 0.2572
Epoch 5/15
22371/22371 - 74s - loss: 0.1190 - mae: 0.2499 - val_loss: 0.1284 - val_mae: 0.2573
Epoch 6/15
22371/22371 - 73s - loss: 0.1158 - mae: 0.2452 - val_loss: 0.1251 - val_mae: 0.2554
Epoch 7/15
22371/22371 - 73s - loss: 0.1127 - mae: 0.2412 - val_loss: 0.1268 - val_mae: 0.2535
Epoch 8/15
22371/22371 - 73s - loss: 0.1106 - mae: 0.2382 - val_loss: 0.1294 - val_mae: 0.2559
Epoch 9/15
22371/22371 - 65s - loss: 0.1095 - mae: 0.2362 - val_loss: 0.1308 - val_mae: 0.2573
Epoch 10/15
22371/22371 - 73s - loss: 0.1070 - mae: 0.2334 - val_loss: 0.1273 - val_mae: 0.2544
Epoch 11/15
22371/22371 - 65s - loss: 0.1058 - mae: 0.2314 - val_loss: 0.1324 - val_mae: 0.2579
Epoch 12/15
22371/22371 - 65s - loss: 0.1052 - mae: 0.2304 - val_loss: 0.1298 - val_mae: 0.2556
Epoch 13/15
22371/22371 - 73s - loss: 0.1040 - mae: 0.2286 - val_loss: 0.1369 - val_mae: 0.2643
Epoch 14/15
22371/22371 - 73s - loss: 0.1038 - mae: 0.2278 - val_loss: 0.1338 - val_mae: 0.2587
Epoch 15/15
22371/22371 - 73s - loss: 0.1027 - mae: 0.2263 - val_loss: 0.1373 - val_mae: 0.2639


RMSE: 0.33128420211622994 MAE: 0.10694866245976468 
Summary: 
Nodes: 4039 Edges: 88234 Train size: 1022640 Test size: 109978
---------------- RUN 1  ------------------
Params for Embeddings:  {'q': 0.05}  with embedding type:  node2vec
Preprocess transition probs...
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.0s finished
Learning embedding vectors...
Learning embedding vectors done!
Embedded training set size: 1022640
Embedded test set size: 109978
Train test split summary: 
 Train X shape: (1022640, 128) Train y shape: (1022640,) 
 Test X shape: (109978, 128) Test y shape: (109978,)


Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 128)               16512     
_________________________________________________________________
activation_3 (Activation)    (None, 128)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 25)                3225      
_________________________________________________________________
activation_4 (Activation)    (None, 25)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 26        
_________________________________________________________________
activation_5 (Activation)    (None, 1)                 0         
=================================================================
Total params: 19,763
Trainable params: 19,763
Non-trainable params: 0
_________________________________________________________________


Epoch 1/15
22371/22371 - 65s - loss: 0.2551 - mae: 0.3713 - val_loss: 0.1232 - val_mae: 0.2726
Epoch 2/15
22371/22371 - 72s - loss: 0.1446 - mae: 0.2841 - val_loss: 0.1087 - val_mae: 0.2478
Epoch 3/15
22371/22371 - 72s - loss: 0.1273 - mae: 0.2646 - val_loss: 0.1052 - val_mae: 0.2377
Epoch 4/15
22371/22371 - 63s - loss: 0.1184 - mae: 0.2538 - val_loss: 0.1023 - val_mae: 0.2336
Epoch 5/15
22371/22371 - 63s - loss: 0.1131 - mae: 0.2474 - val_loss: 0.1023 - val_mae: 0.2301
Epoch 6/15
22371/22371 - 63s - loss: 0.1103 - mae: 0.2431 - val_loss: 0.1005 - val_mae: 0.2287
Epoch 7/15
22371/22371 - 64s - loss: 0.1075 - mae: 0.2395 - val_loss: 0.1099 - val_mae: 0.2365
Epoch 8/15
22371/22371 - 71s - loss: 0.1051 - mae: 0.2366 - val_loss: 0.1030 - val_mae: 0.2300
Epoch 9/15
22371/22371 - 63s - loss: 0.1040 - mae: 0.2347 - val_loss: 0.1006 - val_mae: 0.2265
Epoch 10/15
22371/22371 - 71s - loss: 0.1028 - mae: 0.2329 - val_loss: 0.1022 - val_mae: 0.2282
Epoch 11/15
22371/22371 - 72s - loss: 0.1012 - mae: 0.2312 - val_loss: 0.0995 - val_mae: 0.2234
Epoch 12/15
22371/22371 - 63s - loss: 0.1000 - mae: 0.2296 - val_loss: 0.1022 - val_mae: 0.2264
Epoch 13/15
22371/22371 - 63s - loss: 0.0988 - mae: 0.2281 - val_loss: 0.1102 - val_mae: 0.2359
Epoch 14/15
22371/22371 - 63s - loss: 0.0983 - mae: 0.2273 - val_loss: 0.1055 - val_mae: 0.2303
Epoch 15/15
22371/22371 - 63s - loss: 0.0978 - mae: 0.2262 - val_loss: 0.1091 - val_mae: 0.2344


RMSE: 0.2580074786248467 MAE: 0.06594955354707305 
Summary: 
Nodes: 4039 Edges: 88234 Train size: 1022640 Test size: 109978
---------------- RUN 2  ------------------
Params for Embeddings:  {'q': 0.1}  with embedding type:  node2vec
Preprocess transition probs...
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.4s finished
Learning embedding vectors...
Learning embedding vectors done!
Embedded training set size: 1022640
Embedded test set size: 109978
Train test split summary: 
 Train X shape: (1022640, 128) Train y shape: (1022640,) 
 Test X shape: (109978, 128) Test y shape: (109978,)


Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_6 (Dense)              (None, 128)               16512     
_________________________________________________________________
activation_6 (Activation)    (None, 128)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 25)                3225      
_________________________________________________________________
activation_7 (Activation)    (None, 25)                0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 26        
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 19,763
Trainable params: 19,763
Non-trainable params: 0
_________________________________________________________________


Epoch 1/15
22371/22371 - 73s - loss: 0.2460 - mae: 0.3655 - val_loss: 0.1214 - val_mae: 0.2650
Epoch 2/15
22371/22371 - 64s - loss: 0.1387 - mae: 0.2789 - val_loss: 0.1068 - val_mae: 0.2427
Epoch 3/15
22371/22371 - 64s - loss: 0.1237 - mae: 0.2609 - val_loss: 0.1005 - val_mae: 0.2275
Epoch 4/15
22371/22371 - 73s - loss: 0.1152 - mae: 0.2503 - val_loss: 0.1013 - val_mae: 0.2271
Epoch 5/15
22371/22371 - 65s - loss: 0.1104 - mae: 0.2442 - val_loss: 0.1050 - val_mae: 0.2300
Epoch 6/15
22371/22371 - 65s - loss: 0.1073 - mae: 0.2400 - val_loss: 0.0950 - val_mae: 0.2176
Epoch 7/15
22371/22371 - 65s - loss: 0.1046 - mae: 0.2365 - val_loss: 0.0985 - val_mae: 0.2209
Epoch 8/15
22371/22371 - 72s - loss: 0.1028 - mae: 0.2341 - val_loss: 0.0958 - val_mae: 0.2182
Epoch 9/15
22371/22371 - 64s - loss: 0.1016 - mae: 0.2321 - val_loss: 0.0937 - val_mae: 0.2140
Epoch 10/15
22371/22371 - 72s - loss: 0.1001 - mae: 0.2303 - val_loss: 0.0965 - val_mae: 0.2176
Epoch 11/15
22371/22371 - 72s - loss: 0.0987 - mae: 0.2288 - val_loss: 0.0974 - val_mae: 0.2163
Epoch 12/15
22371/22371 - 64s - loss: 0.0981 - mae: 0.2275 - val_loss: 0.0985 - val_mae: 0.2163
Epoch 13/15
22371/22371 - 72s - loss: 0.0969 - mae: 0.2262 - val_loss: 0.0990 - val_mae: 0.2213
Epoch 14/15
22371/22371 - 72s - loss: 0.0960 - mae: 0.2250 - val_loss: 0.0917 - val_mae: 0.2074
Epoch 15/15
22371/22371 - 63s - loss: 0.0957 - mae: 0.2242 - val_loss: 0.0948 - val_mae: 0.2131


RMSE: 0.21752828464366403 MAE: 0.04706395824619469 
Summary: 
Nodes: 4039 Edges: 88234 Train size: 1022640 Test size: 109978
---------------- RUN 3  ------------------
Params for Embeddings:  {'q': 0.3}  with embedding type:  node2vec
Preprocess transition probs...
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.5s finished
Learning embedding vectors...
Learning embedding vectors done!
Embedded training set size: 1022640
Embedded test set size: 109978
Train test split summary: 
 Train X shape: (1022640, 128) Train y shape: (1022640,) 
 Test X shape: (109978, 128) Test y shape: (109978,)


Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 128)               16512     
_________________________________________________________________
activation_9 (Activation)    (None, 128)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 25)                3225      
_________________________________________________________________
activation_10 (Activation)   (None, 25)                0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_11 (Dense)             (None, 1)                 26        
_________________________________________________________________
activation_11 (Activation)   (None, 1)                 0         
=================================================================
Total params: 19,763
Trainable params: 19,763
Non-trainable params: 0
_________________________________________________________________


Epoch 1/15
22371/22371 - 65s - loss: 0.2576 - mae: 0.3727 - val_loss: 0.1406 - val_mae: 0.2850
Epoch 2/15
22371/22371 - 72s - loss: 0.1432 - mae: 0.2833 - val_loss: 0.1216 - val_mae: 0.2643
Epoch 3/15
22371/22371 - 65s - loss: 0.1270 - mae: 0.2648 - val_loss: 0.1137 - val_mae: 0.2482
Epoch 4/15
22371/22371 - 64s - loss: 0.1190 - mae: 0.2554 - val_loss: 0.1206 - val_mae: 0.2509
Epoch 5/15
22371/22371 - 64s - loss: 0.1143 - mae: 0.2494 - val_loss: 0.1165 - val_mae: 0.2476
Epoch 6/15
22371/22371 - 63s - loss: 0.1112 - mae: 0.2452 - val_loss: 0.1148 - val_mae: 0.2421
Epoch 7/15
22371/22371 - 72s - loss: 0.1075 - mae: 0.2410 - val_loss: 0.1261 - val_mae: 0.2482
Epoch 8/15
22371/22371 - 72s - loss: 0.1054 - mae: 0.2382 - val_loss: 0.1172 - val_mae: 0.2380
Epoch 9/15
22371/22371 - 64s - loss: 0.1034 - mae: 0.2355 - val_loss: 0.1223 - val_mae: 0.2418
Epoch 10/15
22371/22371 - 64s - loss: 0.1024 - mae: 0.2340 - val_loss: 0.1207 - val_mae: 0.2410
Epoch 11/15
22371/22371 - 72s - loss: 0.1011 - mae: 0.2324 - val_loss: 0.1192 - val_mae: 0.2372
Epoch 12/15
22371/22371 - 72s - loss: 0.1000 - mae: 0.2305 - val_loss: 0.1232 - val_mae: 0.2411
Epoch 13/15
22371/22371 - 64s - loss: 0.0984 - mae: 0.2287 - val_loss: 0.1277 - val_mae: 0.2451
Epoch 14/15
22371/22371 - 64s - loss: 0.0979 - mae: 0.2278 - val_loss: 0.1228 - val_mae: 0.2411
Epoch 15/15
22371/22371 - 64s - loss: 0.0966 - mae: 0.2263 - val_loss: 0.1300 - val_mae: 0.2431


RMSE: 0.28267806860278866 MAE: 0.07934314135554384 
Summary: 
Nodes: 4039 Edges: 88234 Train size: 1022640 Test size: 109978
---------------- RUN 4  ------------------
Params for Embeddings:  {'q': 0.5}  with embedding type:  node2vec
Preprocess transition probs...
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.5s finished
Learning embedding vectors...
Learning embedding vectors done!
Embedded training set size: 1022640
Embedded test set size: 109978
Train test split summary: 
 Train X shape: (1022640, 128) Train y shape: (1022640,) 
 Test X shape: (109978, 128) Test y shape: (109978,)


Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_12 (Dense)             (None, 128)               16512     
_________________________________________________________________
activation_12 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 25)                3225      
_________________________________________________________________
activation_13 (Activation)   (None, 25)                0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 26        
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 19,763
Trainable params: 19,763
Non-trainable params: 0
_________________________________________________________________


Epoch 1/15
22371/22371 - 73s - loss: 0.2486 - mae: 0.3679 - val_loss: 0.1276 - val_mae: 0.2710
Epoch 2/15
22371/22371 - 72s - loss: 0.1402 - mae: 0.2802 - val_loss: 0.1157 - val_mae: 0.2514
Epoch 3/15
22371/22371 - 65s - loss: 0.1238 - mae: 0.2607 - val_loss: 0.1074 - val_mae: 0.2372
Epoch 4/15
22371/22371 - 64s - loss: 0.1145 - mae: 0.2493 - val_loss: 0.1093 - val_mae: 0.2356
Epoch 5/15
22371/22371 - 64s - loss: 0.1092 - mae: 0.2426 - val_loss: 0.1086 - val_mae: 0.2354
Epoch 6/15
22371/22371 - 64s - loss: 0.1060 - mae: 0.2380 - val_loss: 0.1067 - val_mae: 0.2321
Epoch 7/15
22371/22371 - 64s - loss: 0.1032 - mae: 0.2346 - val_loss: 0.1196 - val_mae: 0.2428
Epoch 8/15
22371/22371 - 65s - loss: 0.1013 - mae: 0.2316 - val_loss: 0.1068 - val_mae: 0.2302
Epoch 9/15
22371/22371 - 72s - loss: 0.1003 - mae: 0.2303 - val_loss: 0.1116 - val_mae: 0.2338
Epoch 10/15
22371/22371 - 64s - loss: 0.0989 - mae: 0.2287 - val_loss: 0.1155 - val_mae: 0.2380
Epoch 11/15
22371/22371 - 72s - loss: 0.0973 - mae: 0.2266 - val_loss: 0.1117 - val_mae: 0.2295
Epoch 12/15
22371/22371 - 73s - loss: 0.0963 - mae: 0.2252 - val_loss: 0.1139 - val_mae: 0.2301
Epoch 13/15
22371/22371 - 73s - loss: 0.0959 - mae: 0.2246 - val_loss: 0.1154 - val_mae: 0.2362
Epoch 14/15
22371/22371 - 64s - loss: 0.0947 - mae: 0.2231 - val_loss: 0.1280 - val_mae: 0.2459
Epoch 15/15
22371/22371 - 64s - loss: 0.0943 - mae: 0.2226 - val_loss: 0.1185 - val_mae: 0.2339


RMSE: 0.2601308883434636 MAE: 0.06735892633072069 
Summary: 
Nodes: 4039 Edges: 88234 Train size: 1022640 Test size: 109978
---------------- RUN 5  ------------------
Params for Embeddings:  {'q': 0.7}  with embedding type:  node2vec
Preprocess transition probs...
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.6s finished
Learning embedding vectors...
Learning embedding vectors done!
Embedded training set size: 1022640
Embedded test set size: 109978
Train test split summary: 
 Train X shape: (1022640, 128) Train y shape: (1022640,) 
 Test X shape: (109978, 128) Test y shape: (109978,)


Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 128)               16512     
_________________________________________________________________
activation_15 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 25)                3225      
_________________________________________________________________
activation_16 (Activation)   (None, 25)                0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_17 (Dense)             (None, 1)                 26        
_________________________________________________________________
activation_17 (Activation)   (None, 1)                 0         
=================================================================
Total params: 19,763
Trainable params: 19,763
Non-trainable params: 0
_________________________________________________________________


Epoch 1/15
22371/22371 - 65s - loss: 0.2586 - mae: 0.3741 - val_loss: 0.1312 - val_mae: 0.2758
Epoch 2/15
22371/22371 - 65s - loss: 0.1437 - mae: 0.2848 - val_loss: 0.1211 - val_mae: 0.2615
Epoch 3/15
22371/22371 - 64s - loss: 0.1285 - mae: 0.2666 - val_loss: 0.1156 - val_mae: 0.2510
Epoch 4/15
22371/22371 - 73s - loss: 0.1205 - mae: 0.2568 - val_loss: 0.1128 - val_mae: 0.2489
Epoch 5/15
22371/22371 - 64s - loss: 0.1156 - mae: 0.2503 - val_loss: 0.1084 - val_mae: 0.2423
Epoch 6/15
22371/22371 - 72s - loss: 0.1121 - mae: 0.2457 - val_loss: 0.1086 - val_mae: 0.2426
Epoch 7/15
22371/22371 - 65s - loss: 0.1098 - mae: 0.2423 - val_loss: 0.1166 - val_mae: 0.2507
Epoch 8/15
22371/22371 - 73s - loss: 0.1076 - mae: 0.2395 - val_loss: 0.1109 - val_mae: 0.2407
Epoch 9/15
22371/22371 - 72s - loss: 0.1055 - mae: 0.2367 - val_loss: 0.1094 - val_mae: 0.2425
Epoch 10/15
22371/22371 - 65s - loss: 0.1042 - mae: 0.2348 - val_loss: 0.1098 - val_mae: 0.2408
Epoch 11/15
22371/22371 - 64s - loss: 0.1035 - mae: 0.2334 - val_loss: 0.1102 - val_mae: 0.2402
Epoch 12/15
22371/22371 - 72s - loss: 0.1025 - mae: 0.2320 - val_loss: 0.1130 - val_mae: 0.2414
Epoch 13/15
22371/22371 - 65s - loss: 0.1013 - mae: 0.2303 - val_loss: 0.1178 - val_mae: 0.2449
Epoch 14/15
22371/22371 - 72s - loss: 0.1007 - mae: 0.2289 - val_loss: 0.1203 - val_mae: 0.2518
Epoch 15/15
22371/22371 - 72s - loss: 0.0998 - mae: 0.2276 - val_loss: 0.1176 - val_mae: 0.2448


RMSE: 0.2723238634471373 MAE: 0.07399661750531925 
Summary: 
Nodes: 4039 Edges: 88234 Train size: 1022640 Test size: 109978
---------------- RUN 6  ------------------
Params for Embeddings:  {'q': 1}  with embedding type:  node2vec
Preprocess transition probs...
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.7s finished
Learning embedding vectors...
Learning embedding vectors done!
Embedded training set size: 1022640
Embedded test set size: 109978
Train test split summary: 
 Train X shape: (1022640, 128) Train y shape: (1022640,) 
 Test X shape: (109978, 128) Test y shape: (109978,)


Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_18 (Dense)             (None, 128)               16512     
_________________________________________________________________
activation_18 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 25)                3225      
_________________________________________________________________
activation_19 (Activation)   (None, 25)                0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 26        
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 19,763
Trainable params: 19,763
Non-trainable params: 0
_________________________________________________________________


Epoch 1/15
22371/22371 - 73s - loss: 0.2453 - mae: 0.3653 - val_loss: 0.1327 - val_mae: 0.2780
Epoch 2/15
22371/22371 - 72s - loss: 0.1398 - mae: 0.2803 - val_loss: 0.1154 - val_mae: 0.2517
Epoch 3/15
22371/22371 - 73s - loss: 0.1245 - mae: 0.2621 - val_loss: 0.1026 - val_mae: 0.2358
Epoch 4/15
22371/22371 - 73s - loss: 0.1160 - mae: 0.2521 - val_loss: 0.1056 - val_mae: 0.2353
Epoch 5/15
22371/22371 - 73s - loss: 0.1109 - mae: 0.2454 - val_loss: 0.1052 - val_mae: 0.2314
Epoch 6/15
22371/22371 - 64s - loss: 0.1076 - mae: 0.2411 - val_loss: 0.1034 - val_mae: 0.2301
Epoch 7/15
22371/22371 - 64s - loss: 0.1049 - mae: 0.2372 - val_loss: 0.1047 - val_mae: 0.2297
Epoch 8/15
22371/22371 - 72s - loss: 0.1031 - mae: 0.2350 - val_loss: 0.1041 - val_mae: 0.2279
Epoch 9/15
22371/22371 - 64s - loss: 0.1016 - mae: 0.2327 - val_loss: 0.1042 - val_mae: 0.2270
Epoch 10/15
22371/22371 - 72s - loss: 0.1006 - mae: 0.2310 - val_loss: 0.1052 - val_mae: 0.2307
Epoch 11/15
22371/22371 - 64s - loss: 0.0990 - mae: 0.2287 - val_loss: 0.1082 - val_mae: 0.2307
Epoch 12/15
22371/22371 - 72s - loss: 0.0978 - mae: 0.2272 - val_loss: 0.1105 - val_mae: 0.2342
Epoch 13/15
22371/22371 - 64s - loss: 0.0968 - mae: 0.2258 - val_loss: 0.1127 - val_mae: 0.2329
Epoch 14/15
22371/22371 - 72s - loss: 0.0956 - mae: 0.2240 - val_loss: 0.1111 - val_mae: 0.2351
Epoch 15/15
22371/22371 - 64s - loss: 0.0956 - mae: 0.2237 - val_loss: 0.1148 - val_mae: 0.2371


RMSE: 0.2538148445307164 MAE: 0.0643128625725145 
Summary: 
Nodes: 4039 Edges: 88234 Train size: 1022640 Test size: 109978
