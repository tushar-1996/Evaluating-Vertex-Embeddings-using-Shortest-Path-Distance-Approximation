{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unb4OGxERqQI",
        "outputId": "4ded7d6d-056e-460e-b172-b6fb3563ad46"
      },
      "source": [
        "import gdown\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import networkx as nx\n",
        "import csv\n",
        "\n",
        "!mkdir datasets\n",
        "!pip install pyvis\n",
        "from pyvis.network import Network\n",
        "\n",
        "#############################################################################################\n",
        "# Youtube DATASET DOWNLOADS  source: http://datasets.syr.edu/pages/datasets.html\n",
        "#############################################################################################\n",
        "!gdown https://drive.google.com/uc?id=12aGrbOZqVMfOP46X8lj5qwqQui4kbMjZ -O datasets/youtube_edges.csv\n",
        "\n",
        "#############################################################################################\n",
        "# Facebook DATASET DOWNLOADS source: https://github.com/fatemehsrz/Shortest_Distance/tree/master/data\n",
        "#############################################################################################\n",
        "# Download facebook dataset edgelist in txt format (extracted from mtx)\n",
        "#!gdown https://drive.google.com/uc?id=1v03XWRternGLDpRfKbRGoMiVX3dpOW3G -O datasets/facebook_edges.txt\n",
        "\n",
        "#############################################################################################\n",
        "# Douban DATASET DOWNLOADS source: http://datasets.syr.edu/pages/datasets.html\n",
        "#############################################################################################\n",
        "# Download blogcatalog dataset edgelist in cvs format\n",
        "!gdown https://drive.google.com/uc?id=1ssjgKF5WpiXcIk7DfF6BXwPoWkqr5rOS -O datasets/douban_edges.csv\n",
        "!gdown https://drive.google.com/uc?id=174k2qDmDhXrKFivGD00jBWAvJp9b1kiq -O HARP.zip\n",
        "!unzip HARP.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyvis\n",
            "  Downloading pyvis-0.1.9-py3-none-any.whl (23 kB)\n",
            "Collecting jsonpickle>=1.4.1\n",
            "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.7/dist-packages (from pyvis) (2.11.3)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from pyvis) (5.5.0)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.7/dist-packages (from pyvis) (2.6.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->pyvis) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->pyvis) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->pyvis) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->pyvis) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->pyvis) (5.0.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.3.0->pyvis) (2.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.9.6->pyvis) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle>=1.4.1->pyvis) (4.6.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.3.0->pyvis) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.3.0->pyvis) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle>=1.4.1->pyvis) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle>=1.4.1->pyvis) (3.5.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Installing collected packages: jsonpickle, pyvis\n",
            "Successfully installed jsonpickle-2.0.0 pyvis-0.1.9\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12aGrbOZqVMfOP46X8lj5qwqQui4kbMjZ\n",
            "To: /content/datasets/youtube_edges.csv\n",
            "38.7MB [00:00, 75.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ssjgKF5WpiXcIk7DfF6BXwPoWkqr5rOS\n",
            "To: /content/datasets/douban_edges.csv\n",
            "8.29MB [00:00, 50.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=174k2qDmDhXrKFivGD00jBWAvJp9b1kiq\n",
            "To: /content/HARP.zip\n",
            "13.6MB [00:00, 51.5MB/s]\n",
            "Archive:  HARP.zip\n",
            "   creating: HARP/\n",
            "  inflating: HARP/default.walks.12   \n",
            "   creating: HARP/example_graphs/\n",
            "  inflating: HARP/default.walks.13   \n",
            "  inflating: HARP/Facebook.edges     \n",
            "  inflating: HARP/.DS_Store          \n",
            "  inflating: __MACOSX/HARP/._.DS_Store  \n",
            "  inflating: HARP/default.walks.9    \n",
            "  inflating: HARP/default.walks.0    \n",
            "  inflating: HARP/default.walks.7    \n",
            "  inflating: HARP/LICENSE            \n",
            "  inflating: HARP/requirements.txt   \n",
            "   creating: HARP/bin/\n",
            "  inflating: HARP/default.walks.6    \n",
            "  inflating: HARP/default.walks.1    \n",
            "   creating: HARP/dist/\n",
            "  inflating: HARP/default.walks.8    \n",
            "   creating: HARP/magicgraph.egg-info/\n",
            "  inflating: HARP/Facebook_emd.npy   \n",
            "  inflating: HARP/default.walks.11   \n",
            "  inflating: HARP/README.md          \n",
            "  inflating: HARP/default.walks.10   \n",
            "   creating: HARP/magicgraph/\n",
            "  inflating: HARP/.gitignore         \n",
            "  inflating: HARP/default.walks.4    \n",
            "  inflating: HARP/default.walks.3    \n",
            "  inflating: HARP/default.walks.2    \n",
            "  inflating: HARP/default.walks.5    \n",
            "   creating: HARP/build/\n",
            "   creating: HARP/.git/\n",
            "  inflating: HARP/contributors.txt   \n",
            "  inflating: HARP/Facebook_harp_node2vec_emd.npy  \n",
            "   creating: HARP/src/\n",
            "   creating: HARP/example_graphs/dblp/\n",
            "   creating: HARP/example_graphs/citeseer/\n",
            "   creating: HARP/example_graphs/blogcatalog/\n",
            "  inflating: HARP/bin/sfdp_windows.exe  \n",
            "  inflating: HARP/bin/sfdp_linux     \n",
            "  inflating: HARP/bin/sfdp_osx       \n",
            "  inflating: HARP/dist/magicgraph-0.0.1-py3.8.egg  \n",
            "  inflating: HARP/magicgraph.egg-info/PKG-INFO  \n",
            "  inflating: HARP/magicgraph.egg-info/not-zip-safe  \n",
            "  inflating: HARP/magicgraph.egg-info/SOURCES.txt  \n",
            "  inflating: HARP/magicgraph.egg-info/entry_points.txt  \n",
            "  inflating: HARP/magicgraph.egg-info/top_level.txt  \n",
            "  inflating: HARP/magicgraph.egg-info/dependency_links.txt  \n",
            "  inflating: HARP/magicgraph/LICENSE  \n",
            "  inflating: HARP/magicgraph/CONTRIBUTING.rst  \n",
            "   creating: HARP/magicgraph/dist/\n",
            "   creating: HARP/magicgraph/magicgraph.egg-info/\n",
            "   creating: HARP/magicgraph/tests/\n",
            "  inflating: HARP/magicgraph/MANIFEST.in  \n",
            "   creating: HARP/magicgraph/docs/\n",
            "  inflating: HARP/magicgraph/appveyor.yml  \n",
            "  inflating: HARP/magicgraph/setup.py  \n",
            "  inflating: HARP/magicgraph/.gitignore  \n",
            "  inflating: HARP/magicgraph/tox.ini  \n",
            "  inflating: HARP/magicgraph/AUTHORS.rst  \n",
            "  inflating: HARP/magicgraph/setup.cfg  \n",
            "   creating: HARP/magicgraph/build/\n",
            "  inflating: HARP/magicgraph/README.rst  \n",
            "  inflating: HARP/magicgraph/CHANGELOG.rst  \n",
            "   creating: HARP/magicgraph/.git/\n",
            "   creating: HARP/magicgraph/src/\n",
            "   creating: HARP/build/bdist.macosx-10.9-x86_64/\n",
            "  inflating: HARP/.git/config        \n",
            "   creating: HARP/.git/objects/\n",
            "  inflating: HARP/.git/HEAD          \n",
            "   creating: HARP/.git/info/\n",
            "   creating: HARP/.git/logs/\n",
            "  inflating: HARP/.git/description   \n",
            "   creating: HARP/.git/hooks/\n",
            "   creating: HARP/.git/refs/\n",
            "  inflating: HARP/.git/index         \n",
            "  inflating: HARP/.git/packed-refs   \n",
            "  inflating: HARP/.git/FETCH_HEAD    \n",
            "  inflating: HARP/src/graph_coarsening.py  \n",
            "  inflating: HARP/src/baseline.py    \n",
            "  inflating: HARP/src/scoring.py     \n",
            "  inflating: HARP/src/skipgram.pyc   \n",
            "  inflating: HARP/src/graph_coarsening.pyc  \n",
            "  inflating: HARP/src/baseline.pyc   \n",
            "  inflating: HARP/src/harp.py        \n",
            "  inflating: __MACOSX/HARP/src/._harp.py  \n",
            "  inflating: HARP/src/skipgram.py    \n",
            "  inflating: HARP/src/utils.py       \n",
            "  inflating: HARP/src/utils.pyc      \n",
            "  inflating: HARP/example_graphs/dblp/dblp.mat  \n",
            "  inflating: HARP/example_graphs/citeseer/citeseer.mat  \n",
            "  inflating: HARP/example_graphs/blogcatalog/blogcatalog.mat  \n",
            "  inflating: HARP/magicgraph/dist/magicgraph-0.0.1-py2.7.egg  \n",
            "  inflating: HARP/magicgraph/dist/magicgraph-0.0.1-py3.8.egg  \n",
            "  inflating: HARP/magicgraph/magicgraph.egg-info/PKG-INFO  \n",
            "  inflating: HARP/magicgraph/magicgraph.egg-info/not-zip-safe  \n",
            "  inflating: HARP/magicgraph/magicgraph.egg-info/SOURCES.txt  \n",
            "  inflating: HARP/magicgraph/magicgraph.egg-info/entry_points.txt  \n",
            "  inflating: HARP/magicgraph/magicgraph.egg-info/top_level.txt  \n",
            "  inflating: HARP/magicgraph/magicgraph.egg-info/dependency_links.txt  \n",
            "  inflating: HARP/magicgraph/tests/test_magicgraph.py  \n",
            "  inflating: HARP/magicgraph/docs/index.rst  \n",
            "  inflating: HARP/magicgraph/docs/requirements.txt  \n",
            "  inflating: HARP/magicgraph/docs/contributing.rst  \n",
            "  inflating: HARP/magicgraph/docs/conf.py  \n",
            "  inflating: HARP/magicgraph/docs/spelling_wordlist.txt  \n",
            "  inflating: HARP/magicgraph/docs/usage.rst  \n",
            "  inflating: HARP/magicgraph/docs/installation.rst  \n",
            "  inflating: HARP/magicgraph/docs/authors.rst  \n",
            "  inflating: HARP/magicgraph/docs/readme.rst  \n",
            "  inflating: HARP/magicgraph/docs/changelog.rst  \n",
            "   creating: HARP/magicgraph/docs/reference/\n",
            "   creating: HARP/magicgraph/build/bdist.macosx-10.9-x86_64/\n",
            "   creating: HARP/magicgraph/build/lib/\n",
            "   creating: HARP/magicgraph/build/bdist.macosx-11.4-x86_64/\n",
            "  inflating: HARP/magicgraph/.git/config  \n",
            "   creating: HARP/magicgraph/.git/objects/\n",
            "  inflating: HARP/magicgraph/.git/HEAD  \n",
            "   creating: HARP/magicgraph/.git/info/\n",
            "   creating: HARP/magicgraph/.git/logs/\n",
            "  inflating: HARP/magicgraph/.git/description  \n",
            "   creating: HARP/magicgraph/.git/hooks/\n",
            "   creating: HARP/magicgraph/.git/refs/\n",
            "  inflating: HARP/magicgraph/.git/index  \n",
            "  inflating: HARP/magicgraph/.git/packed-refs  \n",
            "   creating: HARP/magicgraph/src/magicgraph/\n",
            "   creating: HARP/.git/objects/0d/\n",
            "   creating: HARP/.git/objects/92/\n",
            "   creating: HARP/.git/objects/57/\n",
            "   creating: HARP/.git/objects/3b/\n",
            "   creating: HARP/.git/objects/04/\n",
            "   creating: HARP/.git/objects/35/\n",
            "   creating: HARP/.git/objects/67/\n",
            "   creating: HARP/.git/objects/93/\n",
            "   creating: HARP/.git/objects/0e/\n",
            "   creating: HARP/.git/objects/33/\n",
            "   creating: HARP/.git/objects/05/\n",
            "   creating: HARP/.git/objects/9d/\n",
            "   creating: HARP/.git/objects/9c/\n",
            "   creating: HARP/.git/objects/b3/\n",
            "   creating: HARP/.git/objects/da/\n",
            "   creating: HARP/.git/objects/b4/\n",
            "   creating: HARP/.git/objects/d1/\n",
            "   creating: HARP/.git/objects/d8/\n",
            "   creating: HARP/.git/objects/ab/\n",
            "   creating: HARP/.git/objects/e2/\n",
            "   creating: HARP/.git/objects/f4/\n",
            "   creating: HARP/.git/objects/c0/\n",
            "   creating: HARP/.git/objects/ee/\n",
            "   creating: HARP/.git/objects/fc/\n",
            "   creating: HARP/.git/objects/cf/\n",
            "   creating: HARP/.git/objects/e4/\n",
            "   creating: HARP/.git/objects/27/\n",
            "   creating: HARP/.git/objects/pack/\n",
            "   creating: HARP/.git/objects/29/\n",
            "   creating: HARP/.git/objects/87/\n",
            "   creating: HARP/.git/objects/80/\n",
            "   creating: HARP/.git/objects/7b/\n",
            "   creating: HARP/.git/objects/8f/\n",
            "   creating: HARP/.git/objects/7e/\n",
            "   creating: HARP/.git/objects/72/\n",
            "   creating: HARP/.git/objects/44/\n",
            "   creating: HARP/.git/objects/09/\n",
            "   creating: HARP/.git/objects/5d/\n",
            "   creating: HARP/.git/objects/info/\n",
            "   creating: HARP/.git/objects/91/\n",
            "   creating: HARP/.git/objects/65/\n",
            "   creating: HARP/.git/objects/54/\n",
            "   creating: HARP/.git/objects/3f/\n",
            "   creating: HARP/.git/objects/30/\n",
            "   creating: HARP/.git/objects/5b/\n",
            "   creating: HARP/.git/objects/52/\n",
            "   creating: HARP/.git/objects/0f/\n",
            "   creating: HARP/.git/objects/d4/\n",
            "   creating: HARP/.git/objects/a0/\n",
            "   creating: HARP/.git/objects/b1/\n",
            "   creating: HARP/.git/objects/aa/\n",
            "   creating: HARP/.git/objects/b7/\n",
            "   creating: HARP/.git/objects/db/\n",
            "   creating: HARP/.git/objects/a1/\n",
            "   creating: HARP/.git/objects/c4/\n",
            "   creating: HARP/.git/objects/e1/\n",
            "   creating: HARP/.git/objects/cd/\n",
            "   creating: HARP/.git/objects/f9/\n",
            "   creating: HARP/.git/objects/e9/\n",
            "   creating: HARP/.git/objects/e7/\n",
            "   creating: HARP/.git/objects/2c/\n",
            "   creating: HARP/.git/objects/77/\n",
            "   creating: HARP/.git/objects/84/\n",
            "   creating: HARP/.git/objects/24/\n",
            "   creating: HARP/.git/objects/4f/\n",
            "   creating: HARP/.git/objects/12/\n",
            "   creating: HARP/.git/objects/8c/\n",
            "   creating: HARP/.git/objects/71/\n",
            "   creating: HARP/.git/objects/47/\n",
            "   creating: HARP/.git/objects/78/\n",
            "   creating: HARP/.git/objects/13/\n",
            "   creating: HARP/.git/objects/7a/\n",
            "  inflating: HARP/.git/info/exclude  \n",
            "  inflating: HARP/.git/logs/HEAD     \n",
            "   creating: HARP/.git/logs/refs/\n",
            "  inflating: HARP/.git/hooks/commit-msg.sample  \n",
            "  inflating: HARP/.git/hooks/pre-rebase.sample  \n",
            "  inflating: HARP/.git/hooks/pre-commit.sample  \n",
            "  inflating: HARP/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: HARP/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: HARP/.git/hooks/pre-receive.sample  \n",
            "  inflating: HARP/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: HARP/.git/hooks/post-update.sample  \n",
            "  inflating: HARP/.git/hooks/pre-merge-commit.sample  \n",
            "  inflating: HARP/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: HARP/.git/hooks/pre-push.sample  \n",
            "  inflating: HARP/.git/hooks/update.sample  \n",
            "   creating: HARP/.git/refs/heads/\n",
            "   creating: HARP/.git/refs/tags/\n",
            "   creating: HARP/.git/refs/remotes/\n",
            "  inflating: HARP/magicgraph/docs/reference/index.rst  \n",
            "  inflating: HARP/magicgraph/docs/reference/magicgraph.rst  \n",
            "   creating: HARP/magicgraph/build/lib/magicgraph/\n",
            "   creating: HARP/magicgraph/.git/objects/pack/\n",
            "   creating: HARP/magicgraph/.git/objects/info/\n",
            "  inflating: HARP/magicgraph/.git/info/exclude  \n",
            "  inflating: HARP/magicgraph/.git/logs/HEAD  \n",
            "   creating: HARP/magicgraph/.git/logs/refs/\n",
            "  inflating: HARP/magicgraph/.git/hooks/commit-msg.sample  \n",
            "  inflating: HARP/magicgraph/.git/hooks/pre-rebase.sample  \n",
            "  inflating: HARP/magicgraph/.git/hooks/pre-commit.sample  \n",
            "  inflating: HARP/magicgraph/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: HARP/magicgraph/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: HARP/magicgraph/.git/hooks/pre-receive.sample  \n",
            "  inflating: HARP/magicgraph/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: HARP/magicgraph/.git/hooks/post-update.sample  \n",
            "  inflating: HARP/magicgraph/.git/hooks/pre-merge-commit.sample  \n",
            "  inflating: HARP/magicgraph/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: HARP/magicgraph/.git/hooks/pre-push.sample  \n",
            "  inflating: HARP/magicgraph/.git/hooks/update.sample  \n",
            "   creating: HARP/magicgraph/.git/refs/heads/\n",
            "   creating: HARP/magicgraph/.git/refs/tags/\n",
            "   creating: HARP/magicgraph/.git/refs/remotes/\n",
            "  inflating: HARP/magicgraph/src/magicgraph/__init__.py  \n",
            "  inflating: HARP/magicgraph/src/magicgraph/visualization.py  \n",
            "  inflating: HARP/magicgraph/src/magicgraph/generators.py  \n",
            "  inflating: HARP/magicgraph/src/magicgraph/__main__.py  \n",
            "  inflating: HARP/.git/objects/0d/20b6487c61e7d1bde93acf4a14b7a89083a16d  \n",
            "  inflating: HARP/.git/objects/92/8ab39a955fc9ffa22cfb319cda44087427d573  \n",
            "  inflating: HARP/.git/objects/57/221785fb742b6ac034a7ba1202e7cd1e79e59e  \n",
            "  inflating: HARP/.git/objects/3b/e0f32bcb9310b70e35201f32a1f1966b5ea6f6  \n",
            "  inflating: HARP/.git/objects/04/aa03807ac2fe563c47966216e9b81b99d0c3de  \n",
            "  inflating: HARP/.git/objects/35/e3ae4165d0e1944b08e9c9fb52beb636994817  \n",
            "  inflating: HARP/.git/objects/35/065f8ec6be4dd6480e577fd0923bb195ba01c7  \n",
            "  inflating: HARP/.git/objects/67/edf26f7470cc42bede6d79d16b659216fc27a4  \n",
            "  inflating: HARP/.git/objects/93/b978492b6396b355f4dd6d70beea0ed0f5174a  \n",
            "  inflating: HARP/.git/objects/93/f6165266a441c141303a7b75216d3e0f603b18  \n",
            "  inflating: HARP/.git/objects/0e/70e461c3a2c767425bb0645dfa2d9c3cc14951  \n",
            "  inflating: HARP/.git/objects/33/b45cad52c5bb20f67514cd6636268eec3a381e  \n",
            "  inflating: HARP/.git/objects/05/d0ffd438888d6b14cac4066395adc89314f9b9  \n",
            "  inflating: HARP/.git/objects/9d/792a4e3dc6bda94952a120c073b8df65d1702f  \n",
            "  inflating: HARP/.git/objects/9c/d355e51f3cd45587df8fccf15fea0f55f635b6  \n",
            "  inflating: HARP/.git/objects/b3/d0b7e69b083e471d7c0f9023042ebd32ce00a5  \n",
            "  inflating: HARP/.git/objects/b3/478af75dcbe5e5c20f3d2b305524548a1c473f  \n",
            "  inflating: HARP/.git/objects/da/7d8a65af0cf0f7f62872f4b3b39293ee74e97d  \n",
            "  inflating: HARP/.git/objects/b4/8d749d9c8ff1dd4c1b3e258afc4cccab659971  \n",
            "  inflating: HARP/.git/objects/d1/62215dd30bd058ab84229670c3224bb4c0d295  \n",
            "  inflating: HARP/.git/objects/d1/013063e970c8761eae22f295dbd531a9baa826  \n",
            "  inflating: HARP/.git/objects/d8/a2052b8fb280e0305546a4181f09ecf6974ac1  \n",
            "  inflating: HARP/.git/objects/d8/249d608d01fa2628c01a5c25603ef7f8c50222  \n",
            "  inflating: HARP/.git/objects/ab/d4f16ce101c139ab0fb8d39546f7e97960721f  \n",
            "  inflating: HARP/.git/objects/e2/6589542b85c12223bce0ccaa97b26aa29143ab  \n",
            "  inflating: HARP/.git/objects/f4/35d82d63f160587763f62c3902fe77b1671c3b  \n",
            "  inflating: HARP/.git/objects/c0/9ef641653683380003c81c84c7076245bcd8d4  \n",
            "  inflating: HARP/.git/objects/ee/a3991ed0df82902dd0b8166cdc2af0e4274c36  \n",
            "  inflating: HARP/.git/objects/fc/2f823ae1328b1ba614b164dccf6eca99d03be9  \n",
            "  inflating: HARP/.git/objects/cf/477b33c68fb26f99e18c0722788d0de6f55c54  \n",
            "  inflating: HARP/.git/objects/e4/a476e650bd2443fbdfebcf37235060528165da  \n",
            "  inflating: HARP/.git/objects/27/d84072c714c03e6f0c2210dc89d8fffc4ef6e5  \n",
            "  inflating: HARP/.git/objects/29/4920531ede02a48d8edd7f35ad605c724dfaca  \n",
            "  inflating: HARP/.git/objects/87/852cc89cfe3547f5f2af5e14ce7344349255f8  \n",
            "  inflating: HARP/.git/objects/80/98d2426aa4f71ba335b407486048c793e6ec5f  \n",
            "  inflating: HARP/.git/objects/80/be5f7c07d6bb09a8b7644573e1240244d6d513  \n",
            "  inflating: HARP/.git/objects/7b/515d1a908cf27c9787b7963dd5414aaf77a5fa  \n",
            "  inflating: HARP/.git/objects/8f/fdb0cbdce70b341a777097de088603bc8a4a9e  \n",
            "  inflating: HARP/.git/objects/7e/9eb147a3a9c03a73455fec22caf84395835557  \n",
            "  inflating: HARP/.git/objects/7e/db64c557d628255a671e34b512ca39e6e58524  \n",
            "  inflating: HARP/.git/objects/72/a13bf05ca58095f72574bb7adfc2718ae4d029  \n",
            "  inflating: HARP/.git/objects/44/b6fbdb1da406aa16c1cc77613f1acc5729f194  \n",
            "  inflating: HARP/.git/objects/09/2e9daf3c6d189f03565955ffbf2e00ad7656b7  \n",
            "  inflating: HARP/.git/objects/5d/d49d1c1753c4404b3d2ff5468afc8f1ddedffe  \n",
            "  inflating: HARP/.git/objects/91/ea425307d01ea8a5513317bdaa88947b8a9e6b  \n",
            "  inflating: HARP/.git/objects/65/089ca3364f36f541a2a73bddb5d755699325fd  \n",
            "  inflating: HARP/.git/objects/54/010b22bdd0411fe3249a931ac6e9fbe2c01c28  \n",
            "  inflating: HARP/.git/objects/3f/ee24e171fa8ad80d246c3804dd0169e72c7739  \n",
            "  inflating: HARP/.git/objects/30/bc25574a748765185b73a364fafbb52b6035aa  \n",
            "  inflating: HARP/.git/objects/5b/63e59ffb04e3c5c7204fb28fe20850cd7bbd73  \n",
            "  inflating: HARP/.git/objects/5b/8b4e482ad190b1aad0db760c6c93f75376a0d7  \n",
            "  inflating: HARP/.git/objects/52/799c7b989296e9ec3e1caa54e96909f82bd768  \n",
            "  inflating: HARP/.git/objects/0f/1758d9f65db25e8ba129110cabd01f21e5c8a1  \n",
            "  inflating: HARP/.git/objects/0f/66b00330cb22613644ee6e4170b3870e990286  \n",
            "  inflating: HARP/.git/objects/d4/c7a91e158b3018347feb9473453c3e1b734360  \n",
            "  inflating: HARP/.git/objects/a0/2cc577357b29eb6a57b69901ad027b10734549  \n",
            "  inflating: HARP/.git/objects/b1/45837e9667bf0baa6f3cd7d5321918686a8369  \n",
            "  inflating: HARP/.git/objects/aa/0384c55f271738a91877015bc86f173d9c66b0  \n",
            "  inflating: HARP/.git/objects/b7/67ef9324c95cbcff92e65a79bf27edfbc1366f  \n",
            "  inflating: HARP/.git/objects/db/c7ad649a3b375502fe738c80473e8af3b7b45b  \n",
            "  inflating: HARP/.git/objects/a1/c28a5885412a4de85a0e8514cfccc088a5a8ec  \n",
            "  inflating: HARP/.git/objects/c4/ce8080f57881481a27f87cd33386c32c473727  \n",
            "  inflating: HARP/.git/objects/e1/c5c9497dc40ce6ef85a61e747b6a3eb7c45767  \n",
            "  inflating: HARP/.git/objects/cd/3a2a145e19432f0d5bc1f064976778e63c95b0  \n",
            "  inflating: HARP/.git/objects/f9/59b44c7458dd86aba1aeb5a14bf611172c6875  \n",
            "  inflating: HARP/.git/objects/e9/45e6b9986fe8d49cfe7c209088862789e80540  \n",
            "  inflating: HARP/.git/objects/e7/d77cbc5249740b5f9abeae3d052a7ce9ef2754  \n",
            "  inflating: HARP/.git/objects/2c/fcb46f84d345b7243296ae4ddad646be0e3383  \n",
            "  inflating: HARP/.git/objects/77/fc0794810096cb26ebd3093f2500cb3aa72c14  \n",
            "  inflating: HARP/.git/objects/77/f562b3d9d19b09f2a029f7aba5fa52edcd812e  \n",
            "  inflating: HARP/.git/objects/84/900b824e75f7b94038d076bbaefc258873198b  \n",
            "  inflating: HARP/.git/objects/24/ac5e6ce3ee6d09cbcd37e2c7e2836d6a23f7c7  \n",
            "  inflating: HARP/.git/objects/4f/75987c29c2bd0d82468b354e94bc6faccd4fba  \n",
            "  inflating: HARP/.git/objects/12/ce48d7fec6c1d0f2b7448060a8356959f90db4  \n",
            "  inflating: HARP/.git/objects/8c/26effc881a64f43f97998548f46afaf3b9e030  \n",
            "  inflating: HARP/.git/objects/71/d949864f31d5ebdb6c57870c38c313687475c7  \n",
            "  inflating: HARP/.git/objects/71/e3a97d23f64fecb23b7f58a614151ba15630c0  \n",
            "  inflating: HARP/.git/objects/47/14d18c9cec40bbf0d3b3b1d0db8a16aecefba0  \n",
            "  inflating: HARP/.git/objects/78/b6ce11fc66bb984bd67d36ca0c765c1a0b813e  \n",
            "  inflating: HARP/.git/objects/13/9f7d430b673463ab28cf1560f9bd46fd828d76  \n",
            "  inflating: HARP/.git/objects/7a/fd5bc0c7d57027ad1b3a4a868f00c2d9a00e8d  \n",
            "   creating: HARP/.git/logs/refs/heads/\n",
            "   creating: HARP/.git/logs/refs/remotes/\n",
            "  inflating: HARP/.git/refs/heads/master  \n",
            "   creating: HARP/.git/refs/remotes/origin/\n",
            "  inflating: HARP/magicgraph/build/lib/magicgraph/__init__.py  \n",
            "  inflating: HARP/magicgraph/build/lib/magicgraph/visualization.py  \n",
            "  inflating: HARP/magicgraph/build/lib/magicgraph/generators.py  \n",
            "  inflating: HARP/magicgraph/build/lib/magicgraph/__main__.py  \n",
            "  inflating: HARP/magicgraph/.git/objects/pack/pack-da5d8629c32549826dbc3db3843f723826cc2b56.pack  \n",
            "  inflating: HARP/magicgraph/.git/objects/pack/pack-da5d8629c32549826dbc3db3843f723826cc2b56.idx  \n",
            "   creating: HARP/magicgraph/.git/logs/refs/heads/\n",
            "   creating: HARP/magicgraph/.git/logs/refs/remotes/\n",
            "  inflating: HARP/magicgraph/.git/refs/heads/master  \n",
            "   creating: HARP/magicgraph/.git/refs/remotes/origin/\n",
            "  inflating: HARP/.git/logs/refs/heads/master  \n",
            "   creating: HARP/.git/logs/refs/remotes/origin/\n",
            "  inflating: HARP/.git/refs/remotes/origin/HEAD  \n",
            "  inflating: HARP/magicgraph/.git/logs/refs/heads/master  \n",
            "   creating: HARP/magicgraph/.git/logs/refs/remotes/origin/\n",
            "  inflating: HARP/magicgraph/.git/refs/remotes/origin/HEAD  \n",
            "  inflating: HARP/.git/logs/refs/remotes/origin/HEAD  \n",
            "  inflating: HARP/magicgraph/.git/logs/refs/remotes/origin/HEAD  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM0KxifSWXg2"
      },
      "source": [
        "landmark_technique = \"random\"\n",
        "dataset = \"douban\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dA83iYGSL8Q",
        "outputId": "d4d4ade6-d0e1-41d0-de40-6ea726de321d"
      },
      "source": [
        "def read_data(dataset):\n",
        "  if dataset == \"facebook\":\n",
        "      G=nx.read_edgelist(\"./datasets/facebook_edges.txt\")\n",
        "  elif dataset == \"blogcatalog\":\n",
        "      G = nx.read_edgelist('./datasets/blogcatalog_edges.csv', delimiter=',', nodetype=str, encoding=\"utf-8\")\n",
        "  elif dataset == \"douban\":\n",
        "      G = nx.read_edgelist('./datasets/douban_edges.csv', delimiter=',', nodetype=int, encoding=\"utf-8\")\n",
        "      G = nx.relabel.convert_node_labels_to_integers(G, first_label=0, ordering=\"sorted\")\n",
        "      nx.write_edgelist(G,'./datasets/douban_edges.txt')\n",
        "      #mapping = {}\n",
        "      #for v in G.nodes():\n",
        "      #  mapping[v] = str(v)\n",
        "      #G = nx.relabel.relabel_nodes(G, mapping)\n",
        "  elif dataset == \"youtube\":\n",
        "      G = nx.read_edgelist('./datasets/youtube_edges.csv', delimiter=',', nodetype=str, encoding=\"utf-8\")\n",
        "      G = nx.relabel.convert_node_labels_to_integers(G, first_label=0, ordering=\"sorted\")\n",
        "\n",
        "      nx.write_edgelist(G, './datasets/youtube_edges.txt')\n",
        "  elif dataset == \"flickr\":\n",
        "      G=nx.read_edgelist(\"./datasets/flickr_edges.txt\")\n",
        "  else:\n",
        "      print(\"Invalid dataset name\")\n",
        "\n",
        "  nodes = list(G.nodes())\n",
        "  edges = list(G.edges())\n",
        "  num_nodes = len(nodes)\n",
        "  num_edges = len(edges)\n",
        "  print(\"Number of nodes\", num_nodes)\n",
        "  print(\"Number of edges\", num_edges)\n",
        "  return G, nodes, edges, num_nodes, num_edges\n",
        "\n",
        "G, nodes, edges, num_nodes, num_edges = read_data(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of nodes 154907\n",
            "Number of edges 327094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfB_AOigu0gZ",
        "outputId": "c7677840-ea17-4f8f-b55b-e21d6dc182fc"
      },
      "source": [
        "print(min(nodes), max(nodes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 154906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "MMPXeDJISPNn",
        "outputId": "eafce392-a5b1-40ac-c59d-72814c7ad209"
      },
      "source": [
        "!pip install deepwalk\n",
        "from networkx.algorithms.community.modularity_max import greedy_modularity_communities\n",
        "from HARP.src.harp import run_coarsening, train_embedding\n",
        "\n",
        "def select_landmarks(num_nodes, landmark_technique,  nodes, is_new_data_split):\n",
        "  print()\n",
        "  if is_new_data_split:\n",
        "    print(\"#### LANDMARK SELECTION ####\")\n",
        "\n",
        "    # Select number of landmark nodes\n",
        "    if (num_nodes>10000):\n",
        "      k1=3\n",
        "      k2=1\n",
        "    else:\n",
        "      k1=100\n",
        "      k2=11\n",
        "\n",
        "    # Select training landmarks\n",
        "    if landmark_technique == \"random\":\n",
        "      print(\"Selecting landmarks randomly...\")\n",
        "      k1_nodes = random.sample(nodes,k1)\n",
        "    elif landmark_technique == \"coarsening\":\n",
        "      print(\"Coarsening graph...\")\n",
        "      %cd HARP\n",
        "      recursive_node_assosiations=run_coarsening(\"../datasets/\"+dataset+\"_edges.txt\", None, \"edgelist\")[1]\n",
        "      #embeddings = train_embedding(\"line\", \"Facebook_HARP_line.npx\", \"../datasets/facebook_edges.txt\", \"network\")\n",
        "      %cd ..\n",
        "      for rec_level in recursive_node_assosiations[::-1]:\n",
        "        rec_l = list(rec_level.keys())\n",
        "        #print(len(rec_l))\n",
        "        if len(rec_l) >= k1:\n",
        "          print(\"Selecting landmarks as coarsened graph...\")\n",
        "          k1_nodes = random.sample(rec_l, k1)\n",
        "          k1_nodes = [str(node) for node in k1_nodes]\n",
        "\n",
        "          break\n",
        "    elif landmark_technique == \"community_detection\":\n",
        "      c = list(greedy_modularity_communities(G))\n",
        "      ratios = []\n",
        "      sum = 0\n",
        "      k1_nodes = []\n",
        "      print(\"Clustering into communities...\")\n",
        "      print(\"number of communities: \",c)\n",
        "      for i in range(len(c)):\n",
        "          percentage = int((len(c[i])/num_nodes)*100)\n",
        "          if percentage==0:\n",
        "              percentage = 1\n",
        "          k1_nodes.extend(random.sample(c[i],percentage))\n",
        "    # I think this is only needed for HARP\n",
        "    print(\"Number of training landmark nodes:\",len(k1_nodes))\n",
        "    remaining_nodes_train = list(set(nodes)-set(k1_nodes))\n",
        "    print(\"number of nodes except training (landmark) nodes\", len(remaining_nodes_train))\n",
        "\n",
        "    # Select testing landmarks\n",
        "    k2_nodes = random.sample(remaining_nodes_train,k2)\n",
        "\n",
        "    print(\"Number of testing landmark nodes:\",len(k2_nodes))\n",
        "    remaining_nodes_test = list(set(nodes)-set(k2_nodes))\n",
        "    print(\"number of nodes except testing (landmark) nodes\", len(remaining_nodes_test))\n",
        "    print(k1_nodes)\n",
        "    return k1_nodes, k2_nodes, remaining_nodes_train, remaining_nodes_test\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "k1_nodes, k2_nodes, remaining_nodes_train, remaining_nodes_test = select_landmarks(num_nodes, landmark_technique, nodes, True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepwalk\n",
            "  Downloading deepwalk-1.0.3-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: psutil>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (5.4.8)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (0.37.0)\n",
            "Requirement already satisfied: scipy>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (1.4.1)\n",
            "Requirement already satisfied: six>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (1.15.0)\n",
            "Requirement already satisfied: gensim>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (3.6.0)\n",
            "Requirement already satisfied: Cython>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from deepwalk) (0.29.24)\n",
            "Collecting argparse>=1.2.1\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting futures>=2.1.6\n",
            "  Downloading futures-3.1.1-py3-none-any.whl (2.8 kB)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=1.0.0->deepwalk) (5.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim>=1.0.0->deepwalk) (1.19.5)\n",
            "Installing collected packages: futures, argparse, deepwalk\n",
            "Successfully installed argparse-1.4.0 deepwalk-1.0.3 futures-3.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/HARP/src\n",
            "\n",
            "#### LANDMARK SELECTION ####\n",
            "Selecting landmarks randomly...\n",
            "Number of training landmark nodes: 3\n",
            "number of nodes except training (landmark) nodes 154904\n",
            "Number of testing landmark nodes: 1\n",
            "number of nodes except testing (landmark) nodes 154906\n",
            "[100642, 105822, 55852]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEvBY0jBSSy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f5b020-2ec0-48d2-e5fe-5e11175a6da3"
      },
      "source": [
        "def generate_and_save_train_data(G, k1_nodes, is_new_data_split, dataset, landmark_technique):\n",
        "  train_set = []\n",
        "  if is_new_data_split:\n",
        "    for u in k1_nodes:\n",
        "      for v in remaining_nodes_train:\n",
        "          if nx.has_path(G, u, v):\n",
        "            shortest_path = nx.shortest_path(G, u, v)\n",
        "            length = 1\n",
        "            for i in range(len(shortest_path)-1):\n",
        "              train_set.append((shortest_path[0], shortest_path[i+1], length))\n",
        "              length +=1\n",
        "\n",
        "    print(\"Size of total training set before omission:\",len(train_set))\n",
        "\n",
        "    f_train = open('./datasets/train_'+dataset+'_'+landmark_technique+'.txt', 'w')\n",
        "    for i in range(len(train_set)): \n",
        "      if (1< train_set[i][2] <= 6):\n",
        "        f_train.write(str(train_set[i][0])+' '+str(train_set[i][1])+' '+str(train_set[i][2]) )\n",
        "        f_train.write('\\n')\n",
        "              \n",
        "    f_train.close()\n",
        "    print(\"Train file written\")\n",
        "\n",
        "generate_and_save_train_data(G, k1_nodes, True, dataset, landmark_technique)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of total training set before omission: 20027051\n",
            "Train file written\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjH94yFmSVBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a435075-c8a2-4709-8a9e-d89e6cbe6dd9"
      },
      "source": [
        "def generate_and_save_test_data(G, k2_nodes, is_new_data_split, dataset, landmark_technique):\n",
        "  test_set = []\n",
        "  if is_new_data_split:\n",
        "    for u in k2_nodes:\n",
        "      for v in remaining_nodes_test:\n",
        "        if nx.has_path(G, u, v):\n",
        "          shortest_path = nx.shortest_path(G,u,v)\n",
        "          length = 1\n",
        "          for i in range(len(shortest_path) - 1):\n",
        "            test_set.append((shortest_path[0], shortest_path[i+1], length))\n",
        "            length += 1\n",
        "    print(\"Size of total training set before omission:\",len(test_set))\n",
        "\n",
        "    f_test = open('./datasets/test_'+dataset+'_'+landmark_technique+'.txt', 'w')\n",
        "    for i in range(len(test_set)):\n",
        "      if (1< test_set[i][2] <= 6):\n",
        "        f_test.write(str(test_set[i][0])+' '+ str(test_set[i][1]) +' '+ str(test_set[i][2]) )\n",
        "        f_test.write('\\n')\n",
        "\n",
        "    f_test.close()\n",
        "    print(\"Test file written\")\n",
        "generate_and_save_test_data(G, k2_nodes, True, dataset, landmark_technique)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of total training set before omission: 6273941\n",
            "Test file written\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "822CXk0eSX4V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "cae4c58f-c2d3-4c78-e1ac-181c51b7e9b1"
      },
      "source": [
        " def visualise_graph_with_landmarks(G, k1_nodes, landmark_technique):\n",
        "  net = Network(notebook=True)\n",
        "  net.from_nx(G)\n",
        "  # Coloring landmark nodes\n",
        "  for node_id in k1_nodes:\n",
        "    net.node_map[str(node_id)]['shape'] = 'box'\n",
        "    net.node_map[str(node_id)]['color'] = 'red'\n",
        "  net.save_graph('graph_'+dataset+'_'+landmark_technique+'.html')\n",
        "\n",
        "visualise_graph_with_landmarks(G, k1_nodes, landmark_technique)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-201032551685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m  \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'graph_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlandmark_technique\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mvisualise_graph_with_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk1_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmark_technique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-201032551685>\u001b[0m in \u001b[0;36mvisualise_graph_with_landmarks\u001b[0;34m(G, k1_nodes, landmark_technique)\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0;31m# Coloring landmark nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mnode_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk1_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'box'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'color'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m  \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'graph_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlandmark_technique\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '100642'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUDLSF0LrqEi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}