{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open('node2vec_optim.txt', 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = str(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Number of training pairs: 1022640\\nPath Lengths in train set:  [2 3 4 5 6]  Size of each length:  [389132 320865 221561  72701  18381]\\nNumber of testing pairs: 109978\\nPath Lengths in test set:  [2 3 4 5 6]  Size of each length:  [42666 35029 23663  6947  1673]\\nNumber of nodes 4039\\nNumber of edges 88234\\nParams for Embeddings:  {'p': 0.25, 'q': 0.25}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   27.1s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_0.25_q_0.25.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 68s - loss: 0.1736 - mae: 0.3057 - val_loss: 0.0502 - val_mae: 0.1626\\nEpoch 2/15\\n22371/22371 - 72s - loss: 0.1211 - mae: 0.2539 - val_loss: 0.0370 - val_mae: 0.1299\\nEpoch 3/15\\n22371/22371 - 69s - loss: 0.1124 - mae: 0.2431 - val_loss: 0.0643 - val_mae: 0.1783\\nEpoch 4/15\\n22371/22371 - 69s - loss: 0.1091 - mae: 0.2386 - val_loss: 0.0341 - val_mae: 0.1229\\nEpoch 5/15\\n22371/22371 - 66s - loss: 0.1059 - mae: 0.2350 - val_loss: 0.0308 - val_mae: 0.1105\\nEpoch 6/15\\n22371/22371 - 58s - loss: 0.1045 - mae: 0.2329 - val_loss: 0.0474 - val_mae: 0.1387\\nEpoch 7/15\\n22371/22371 - 71s - loss: 0.1027 - mae: 0.2309 - val_loss: 0.0322 - val_mae: 0.1215\\nEpoch 8/15\\n22371/22371 - 68s - loss: 0.1013 - mae: 0.2288 - val_loss: 0.0337 - val_mae: 0.1229\\nEpoch 9/15\\n22371/22371 - 75s - loss: 0.1007 - mae: 0.2285 - val_loss: 0.0297 - val_mae: 0.1144\\nEpoch 10/15\\n22371/22371 - 61s - loss: 0.1002 - mae: 0.2274 - val_loss: 0.0267 - val_mae: 0.1209\\nEpoch 11/15\\n22371/22371 - 63s - loss: 0.0998 - mae: 0.2268 - val_loss: 0.0824 - val_mae: 0.1858\\nEpoch 12/15\\n22371/22371 - 65s - loss: 0.0984 - mae: 0.2253 - val_loss: 0.0236 - val_mae: 0.1009\\nEpoch 13/15\\n22371/22371 - 72s - loss: 0.0985 - mae: 0.2250 - val_loss: 0.0333 - val_mae: 0.1231\\nEpoch 14/15\\n22371/22371 - 72s - loss: 0.0976 - mae: 0.2241 - val_loss: 0.0228 - val_mae: 0.0959\\nEpoch 15/15\\n22371/22371 - 72s - loss: 0.0970 - mae: 0.2237 - val_loss: 0.0260 - val_mae: 0.1005\\n\\n\\nRMSE: 0.24311052967084018 MAE: 0.058229827783738565 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.942207\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.97507167 0.90748827 0.94832199 0.8952979  0.99012567 0.        ]\\n/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\\n  _warn_prf(average, modifier, msg_start, len(result))\\nRecall: \\t [0.9965312  0.96108938 0.85382242 0.88253923 0.65929468 0.        ]\\nF1 score: \\t [0.98568464 0.93352004 0.89859456 0.88887278 0.79153211 0.        ]\\nParams for Embeddings:  {'p': 0.25, 'q': 0.5}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   27.2s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_0.25_q_0.5.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 70s - loss: 0.1804 - mae: 0.3133 - val_loss: 0.0437 - val_mae: 0.1447\\nEpoch 2/15\\n22371/22371 - 80s - loss: 0.1248 - mae: 0.2594 - val_loss: 0.0350 - val_mae: 0.1223\\nEpoch 3/15\\n22371/22371 - 78s - loss: 0.1167 - mae: 0.2491 - val_loss: 0.0333 - val_mae: 0.1239\\nEpoch 4/15\\n22371/22371 - 78s - loss: 0.1122 - mae: 0.2435 - val_loss: 0.0498 - val_mae: 0.1570\\nEpoch 5/15\\n22371/22371 - 80s - loss: 0.1089 - mae: 0.2395 - val_loss: 0.0281 - val_mae: 0.1083\\nEpoch 6/15\\n22371/22371 - 65s - loss: 0.1070 - mae: 0.2370 - val_loss: 0.0300 - val_mae: 0.1230\\nEpoch 7/15\\n22371/22371 - 76s - loss: 0.1057 - mae: 0.2355 - val_loss: 0.0289 - val_mae: 0.1140\\nEpoch 8/15\\n22371/22371 - 73s - loss: 0.1043 - mae: 0.2336 - val_loss: 0.0286 - val_mae: 0.1178\\nEpoch 9/15\\n22371/22371 - 77s - loss: 0.1033 - mae: 0.2326 - val_loss: 0.0253 - val_mae: 0.1030\\nEpoch 10/15\\n22371/22371 - 76s - loss: 0.1024 - mae: 0.2316 - val_loss: 0.0282 - val_mae: 0.1137\\nEpoch 11/15\\n22371/22371 - 55s - loss: 0.1018 - mae: 0.2309 - val_loss: 0.0292 - val_mae: 0.1203\\nEpoch 12/15\\n22371/22371 - 71s - loss: 0.1015 - mae: 0.2301 - val_loss: 0.0287 - val_mae: 0.1149\\nEpoch 13/15\\n22371/22371 - 54s - loss: 0.1011 - mae: 0.2295 - val_loss: 0.0322 - val_mae: 0.1253\\nEpoch 14/15\\n22371/22371 - 51s - loss: 0.1002 - mae: 0.2288 - val_loss: 0.0231 - val_mae: 0.1027\\nEpoch 15/15\\n22371/22371 - 60s - loss: 0.1001 - mae: 0.2284 - val_loss: 0.0296 - val_mae: 0.1196\\n\\n\\nRMSE: 0.235569345979419 MAE: 0.05545654585462547 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.944562\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.98395411 0.9115548  0.92703709 0.92368697 0.98357964 0.        ]\\n/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\\n  _warn_prf(average, modifier, msg_start, len(result))\\nRecall: \\t [0.99313271 0.95535128 0.87360014 0.888585   0.7160789  0.        ]\\nF1 score: \\t [0.9885221  0.93293932 0.8995257  0.90579604 0.82877897 0.        ]\\nParams for Embeddings:  {'p': 0.25, 'q': 1}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.1s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_0.25_q_1.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 51s - loss: 0.1781 - mae: 0.3095 - val_loss: 0.0458 - val_mae: 0.1412\\nEpoch 2/15\\n22371/22371 - 60s - loss: 0.1263 - mae: 0.2564 - val_loss: 0.0578 - val_mae: 0.1721\\nEpoch 3/15\\n22371/22371 - 57s - loss: 0.1182 - mae: 0.2452 - val_loss: 0.0480 - val_mae: 0.1622\\nEpoch 4/15\\n22371/22371 - 82s - loss: 0.1133 - mae: 0.2385 - val_loss: 0.0466 - val_mae: 0.1517\\nEpoch 5/15\\n22371/22371 - 84s - loss: 0.1107 - mae: 0.2352 - val_loss: 0.0358 - val_mae: 0.1295\\nEpoch 6/15\\n22371/22371 - 76s - loss: 0.1084 - mae: 0.2323 - val_loss: 0.0360 - val_mae: 0.1382\\nEpoch 7/15\\n22371/22371 - 83s - loss: 0.1072 - mae: 0.2304 - val_loss: 0.0470 - val_mae: 0.1585\\nEpoch 8/15\\n22371/22371 - 75s - loss: 0.1059 - mae: 0.2283 - val_loss: 0.0313 - val_mae: 0.1190\\nEpoch 9/15\\n22371/22371 - 78s - loss: 0.1049 - mae: 0.2270 - val_loss: 0.0456 - val_mae: 0.1516\\nEpoch 10/15\\n22371/22371 - 67s - loss: 0.1040 - mae: 0.2257 - val_loss: 0.0390 - val_mae: 0.1469\\nEpoch 11/15\\n22371/22371 - 57s - loss: 0.1030 - mae: 0.2244 - val_loss: 0.0342 - val_mae: 0.1319\\nEpoch 12/15\\n22371/22371 - 61s - loss: 0.1028 - mae: 0.2238 - val_loss: 0.0440 - val_mae: 0.1545\\nEpoch 13/15\\n22371/22371 - 50s - loss: 0.1022 - mae: 0.2229 - val_loss: 0.0384 - val_mae: 0.1415\\nEpoch 14/15\\n22371/22371 - 50s - loss: 0.1013 - mae: 0.2216 - val_loss: 0.0325 - val_mae: 0.1247\\nEpoch 15/15\\n22371/22371 - 50s - loss: 0.1011 - mae: 0.2211 - val_loss: 0.0329 - val_mae: 0.1301\\n\\n\\nRMSE: 0.2457701969093219 MAE: 0.057656985942643076 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.943716\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.         0.98759068 0.91577211 0.92598148 0.90436946 0.85703305\\n 0.        ]\\n/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\\n  _warn_prf(average, modifier, msg_start, len(result))\\nRecall: \\t [0.         0.96995266 0.96685603 0.91302878 0.83719591 0.66646742\\n 0.        ]\\nF1 score: \\t [0.         0.97869221 0.94062101 0.91945952 0.86948722 0.74983188\\n 0.        ]\\nParams for Embeddings:  {'p': 0.25, 'q': 2}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.8s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_0.25_q_2.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 61s - loss: 0.1815 - mae: 0.3144 - val_loss: 0.0640 - val_mae: 0.2011\\nEpoch 2/15\\n22371/22371 - 49s - loss: 0.1242 - mae: 0.2591 - val_loss: 0.0419 - val_mae: 0.1405\\nEpoch 3/15\\n22371/22371 - 59s - loss: 0.1164 - mae: 0.2483 - val_loss: 0.0381 - val_mae: 0.1389\\nEpoch 4/15\\n22371/22371 - 59s - loss: 0.1119 - mae: 0.2424 - val_loss: 0.0461 - val_mae: 0.1478\\nEpoch 5/15\\n22371/22371 - 78s - loss: 0.1090 - mae: 0.2386 - val_loss: 0.0347 - val_mae: 0.1263\\nEpoch 6/15\\n22371/22371 - 59s - loss: 0.1060 - mae: 0.2351 - val_loss: 0.0339 - val_mae: 0.1287\\nEpoch 7/15\\n22371/22371 - 53s - loss: 0.1045 - mae: 0.2334 - val_loss: 0.0301 - val_mae: 0.1195\\nEpoch 8/15\\n22371/22371 - 52s - loss: 0.1034 - mae: 0.2316 - val_loss: 0.0325 - val_mae: 0.1290\\nEpoch 9/15\\n22371/22371 - 50s - loss: 0.1029 - mae: 0.2308 - val_loss: 0.0422 - val_mae: 0.1542\\nEpoch 10/15\\n22371/22371 - 60s - loss: 0.1023 - mae: 0.2296 - val_loss: 0.0287 - val_mae: 0.1161\\nEpoch 11/15\\n22371/22371 - 50s - loss: 0.1009 - mae: 0.2283 - val_loss: 0.0294 - val_mae: 0.1219\\nEpoch 12/15\\n22371/22371 - 49s - loss: 0.1000 - mae: 0.2271 - val_loss: 0.0337 - val_mae: 0.1320\\nEpoch 13/15\\n22371/22371 - 50s - loss: 0.0993 - mae: 0.2264 - val_loss: 0.0306 - val_mae: 0.1271\\nEpoch 14/15\\n22371/22371 - 49s - loss: 0.0989 - mae: 0.2257 - val_loss: 0.0358 - val_mae: 0.1380\\nEpoch 15/15\\n22371/22371 - 59s - loss: 0.0988 - mae: 0.2255 - val_loss: 0.0382 - val_mae: 0.1464\\n\\n\\nRMSE: 0.24687760803084804 MAE: 0.06007565149393515 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.940361\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.98574419 0.91021705 0.92214548 0.86802742 1.        ]\\nRecall: \\t [0.99346084 0.97330783 0.86895153 0.80192889 0.48117155]\\nF1 score: \\t [0.98958747 0.94070579 0.8947586  0.83367003 0.64971751]\\nParams for Embeddings:  {'p': 0.5, 'q': 0.25}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   29.1s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_0.5_q_0.25.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 50s - loss: 0.1816 - mae: 0.3144 - val_loss: 0.0407 - val_mae: 0.1377\\nEpoch 2/15\\n22371/22371 - 50s - loss: 0.1244 - mae: 0.2578 - val_loss: 0.0357 - val_mae: 0.1269\\nEpoch 3/15\\n22371/22371 - 49s - loss: 0.1163 - mae: 0.2461 - val_loss: 0.0348 - val_mae: 0.1218\\nEpoch 4/15\\n22371/22371 - 50s - loss: 0.1118 - mae: 0.2400 - val_loss: 0.0383 - val_mae: 0.1328\\nEpoch 5/15\\n22371/22371 - 49s - loss: 0.1092 - mae: 0.2364 - val_loss: 0.0369 - val_mae: 0.1321\\nEpoch 6/15\\n22371/22371 - 50s - loss: 0.1066 - mae: 0.2333 - val_loss: 0.0372 - val_mae: 0.1252\\nEpoch 7/15\\n22371/22371 - 60s - loss: 0.1061 - mae: 0.2319 - val_loss: 0.0470 - val_mae: 0.1491\\nEpoch 8/15\\n22371/22371 - 56s - loss: 0.1043 - mae: 0.2297 - val_loss: 0.0334 - val_mae: 0.1265\\nEpoch 9/15\\n22371/22371 - 50s - loss: 0.1027 - mae: 0.2278 - val_loss: 0.0320 - val_mae: 0.1215\\nEpoch 10/15\\n22371/22371 - 58s - loss: 0.1023 - mae: 0.2269 - val_loss: 0.0346 - val_mae: 0.1196\\nEpoch 11/15\\n22371/22371 - 50s - loss: 0.1015 - mae: 0.2262 - val_loss: 0.0256 - val_mae: 0.1045\\nEpoch 12/15\\n22371/22371 - 49s - loss: 0.1010 - mae: 0.2251 - val_loss: 0.0304 - val_mae: 0.1078\\nEpoch 13/15\\n22371/22371 - 49s - loss: 0.1000 - mae: 0.2243 - val_loss: 0.0347 - val_mae: 0.1216\\nEpoch 14/15\\n22371/22371 - 50s - loss: 0.1005 - mae: 0.2245 - val_loss: 0.0357 - val_mae: 0.1332\\nEpoch 15/15\\n22371/22371 - 51s - loss: 0.0997 - mae: 0.2233 - val_loss: 0.0276 - val_mae: 0.1125\\n\\n\\nRMSE: 0.21944267033229214 MAE: 0.047936860099292586 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.952172\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.99495509 0.92263067 0.9266956  0.92792664 0.95928571]\\nRecall: \\t [0.98919514 0.95797768 0.89325107 0.93220095 0.80274955]\\nF1 score: \\t [0.99206676 0.93997199 0.90966604 0.93005888 0.87406443]\\nParams for Embeddings:  {'p': 0.5, 'q': 0.5}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   25.1s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_0.5_q_0.5.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 51s - loss: 0.1865 - mae: 0.3146 - val_loss: 0.0543 - val_mae: 0.1666\\nEpoch 2/15\\n22371/22371 - 50s - loss: 0.1307 - mae: 0.2583 - val_loss: 0.0470 - val_mae: 0.1518\\nEpoch 3/15\\n22371/22371 - 69s - loss: 0.1226 - mae: 0.2474 - val_loss: 0.0675 - val_mae: 0.1952\\nEpoch 4/15\\n22371/22371 - 54s - loss: 0.1177 - mae: 0.2414 - val_loss: 0.0407 - val_mae: 0.1435\\nEpoch 5/15\\n22371/22371 - 63s - loss: 0.1151 - mae: 0.2375 - val_loss: 0.0473 - val_mae: 0.1553\\nEpoch 6/15\\n22371/22371 - 51s - loss: 0.1114 - mae: 0.2326 - val_loss: 0.0400 - val_mae: 0.1433\\nEpoch 7/15\\n22371/22371 - 51s - loss: 0.1107 - mae: 0.2310 - val_loss: 0.0490 - val_mae: 0.1630\\nEpoch 8/15\\n22371/22371 - 51s - loss: 0.1089 - mae: 0.2290 - val_loss: 0.0552 - val_mae: 0.1727\\nEpoch 9/15\\n22371/22371 - 50s - loss: 0.1082 - mae: 0.2275 - val_loss: 0.0415 - val_mae: 0.1384\\nEpoch 10/15\\n22371/22371 - 62s - loss: 0.1077 - mae: 0.2271 - val_loss: 0.0440 - val_mae: 0.1513\\nEpoch 11/15\\n22371/22371 - 66s - loss: 0.1062 - mae: 0.2255 - val_loss: 0.0458 - val_mae: 0.1550\\nEpoch 12/15\\n22371/22371 - 53s - loss: 0.1051 - mae: 0.2241 - val_loss: 0.0426 - val_mae: 0.1449\\nEpoch 13/15\\n22371/22371 - 82s - loss: 0.1050 - mae: 0.2233 - val_loss: 0.0544 - val_mae: 0.1717\\nEpoch 14/15\\n22371/22371 - 84s - loss: 0.1051 - mae: 0.2232 - val_loss: 0.0472 - val_mae: 0.1573\\nEpoch 15/15\\n22371/22371 - 71s - loss: 0.1044 - mae: 0.2225 - val_loss: 0.0483 - val_mae: 0.1561\\n\\n\\nRMSE: 0.2924019800983079 MAE: 0.08535343432322828 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.914719\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.9987329  0.84824309 0.90037054 0.86610169 1.        ]\\nRecall: \\t [0.90521727 0.96825487 0.91391624 0.80912624 0.48595338]\\nF1 score: \\t [0.9496785  0.90428453 0.90709282 0.83664508 0.65406275]\\nParams for Embeddings:  {'p': 0.5, 'q': 1}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   29.8s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_0.5_q_1.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 81s - loss: 0.1810 - mae: 0.3104 - val_loss: 0.0735 - val_mae: 0.1937\\nEpoch 2/15\\n22371/22371 - 81s - loss: 0.1300 - mae: 0.2587 - val_loss: 0.0456 - val_mae: 0.1522\\nEpoch 3/15\\n22371/22371 - 85s - loss: 0.1215 - mae: 0.2478 - val_loss: 0.0597 - val_mae: 0.1761\\nEpoch 4/15\\n22371/22371 - 76s - loss: 0.1176 - mae: 0.2416 - val_loss: 0.0623 - val_mae: 0.1783\\nEpoch 5/15\\n22371/22371 - 82s - loss: 0.1140 - mae: 0.2365 - val_loss: 0.0327 - val_mae: 0.1182\\nEpoch 6/15\\n22371/22371 - 75s - loss: 0.1117 - mae: 0.2335 - val_loss: 0.0495 - val_mae: 0.1559\\nEpoch 7/15\\n22371/22371 - 81s - loss: 0.1098 - mae: 0.2312 - val_loss: 0.0557 - val_mae: 0.1764\\nEpoch 8/15\\n22371/22371 - 82s - loss: 0.1084 - mae: 0.2293 - val_loss: 0.0312 - val_mae: 0.1236\\nEpoch 9/15\\n22371/22371 - 83s - loss: 0.1081 - mae: 0.2283 - val_loss: 0.0431 - val_mae: 0.1491\\nEpoch 10/15\\n22371/22371 - 83s - loss: 0.1069 - mae: 0.2268 - val_loss: 0.0368 - val_mae: 0.1302\\nEpoch 11/15\\n22371/22371 - 74s - loss: 0.1063 - mae: 0.2260 - val_loss: 0.0436 - val_mae: 0.1491\\nEpoch 12/15\\n22371/22371 - 81s - loss: 0.1058 - mae: 0.2251 - val_loss: 0.0384 - val_mae: 0.1369\\nEpoch 13/15\\n22371/22371 - 82s - loss: 0.1055 - mae: 0.2245 - val_loss: 0.0489 - val_mae: 0.1675\\nEpoch 14/15\\n22371/22371 - 75s - loss: 0.1044 - mae: 0.2232 - val_loss: 0.0435 - val_mae: 0.1421\\nEpoch 15/15\\n22371/22371 - 80s - loss: 0.1048 - mae: 0.2235 - val_loss: 0.0292 - val_mae: 0.1129\\n\\n\\nRMSE: 0.23150061919821296 MAE: 0.052792376657149614 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.947608\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.         0.98560496 0.93271662 0.91719367 0.8900291  0.97597598\\n 0.        ]\\n/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\\n  _warn_prf(average, modifier, msg_start, len(result))\\nRecall: \\t [0.         0.99013266 0.95849154 0.91324008 0.83647618 0.58278542\\n 0.        ]\\nF1 score: \\t [0.         0.98786362 0.94542843 0.9152126  0.86242208 0.72979042\\n 0.        ]\\nParams for Embeddings:  {'p': 0.5, 'q': 2}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   30.7s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_0.5_q_2.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 76s - loss: 0.1798 - mae: 0.3101 - val_loss: 0.0457 - val_mae: 0.1424\\nEpoch 2/15\\n22371/22371 - 77s - loss: 0.1218 - mae: 0.2541 - val_loss: 0.0323 - val_mae: 0.1188\\nEpoch 3/15\\n22371/22371 - 75s - loss: 0.1133 - mae: 0.2445 - val_loss: 0.0330 - val_mae: 0.1226\\nEpoch 4/15\\n22371/22371 - 69s - loss: 0.1088 - mae: 0.2391 - val_loss: 0.0316 - val_mae: 0.1165\\nEpoch 5/15\\n22371/22371 - 80s - loss: 0.1058 - mae: 0.2355 - val_loss: 0.0239 - val_mae: 0.0972\\nEpoch 6/15\\n22371/22371 - 66s - loss: 0.1037 - mae: 0.2329 - val_loss: 0.0276 - val_mae: 0.1056\\nEpoch 7/15\\n22371/22371 - 54s - loss: 0.1029 - mae: 0.2317 - val_loss: 0.0256 - val_mae: 0.1068\\nEpoch 8/15\\n22371/22371 - 51s - loss: 0.1010 - mae: 0.2296 - val_loss: 0.0329 - val_mae: 0.1245\\nEpoch 9/15\\n22371/22371 - 60s - loss: 0.1001 - mae: 0.2283 - val_loss: 0.0223 - val_mae: 0.0958\\nEpoch 10/15\\n22371/22371 - 49s - loss: 0.0992 - mae: 0.2272 - val_loss: 0.0294 - val_mae: 0.1122\\nEpoch 11/15\\n22371/22371 - 49s - loss: 0.0988 - mae: 0.2264 - val_loss: 0.0222 - val_mae: 0.0974\\nEpoch 12/15\\n22371/22371 - 48s - loss: 0.0982 - mae: 0.2256 - val_loss: 0.0207 - val_mae: 0.0852\\nEpoch 13/15\\n22371/22371 - 68s - loss: 0.0976 - mae: 0.2249 - val_loss: 0.0243 - val_mae: 0.0970\\nEpoch 14/15\\n22371/22371 - 50s - loss: 0.0970 - mae: 0.2242 - val_loss: 0.0328 - val_mae: 0.1193\\nEpoch 15/15\\n22371/22371 - 70s - loss: 0.0959 - mae: 0.2231 - val_loss: 0.0255 - val_mae: 0.1144\\n\\n\\nRMSE: 0.2446206053777723 MAE: 0.059784684209569186 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.940243\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.98364356 0.90482789 0.94200043 0.9104521  0.77581121 0.        ]\\n/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\\n  _warn_prf(average, modifier, msg_start, len(result))\\nRecall: \\t [0.95000703 0.95075509 0.92934117 0.90154023 0.78601315 0.        ]\\nF1 score: \\t [0.96653273 0.92722312 0.93562798 0.90597425 0.78087886 0.        ]\\nParams for Embeddings:  {'p': 1, 'q': 0.25}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.3s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_1_q_0.25.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 62s - loss: 0.1791 - mae: 0.3126 - val_loss: 0.0504 - val_mae: 0.1515\\nEpoch 2/15\\n22371/22371 - 60s - loss: 0.1233 - mae: 0.2584 - val_loss: 0.0472 - val_mae: 0.1477\\nEpoch 3/15\\n22371/22371 - 58s - loss: 0.1152 - mae: 0.2481 - val_loss: 0.0740 - val_mae: 0.1982\\nEpoch 4/15\\n22371/22371 - 60s - loss: 0.1109 - mae: 0.2425 - val_loss: 0.0329 - val_mae: 0.1189\\nEpoch 5/15\\n22371/22371 - 49s - loss: 0.1088 - mae: 0.2398 - val_loss: 0.0275 - val_mae: 0.1116\\nEpoch 6/15\\n22371/22371 - 49s - loss: 0.1066 - mae: 0.2372 - val_loss: 0.0303 - val_mae: 0.1147\\nEpoch 7/15\\n22371/22371 - 49s - loss: 0.1049 - mae: 0.2350 - val_loss: 0.0378 - val_mae: 0.1363\\nEpoch 8/15\\n22371/22371 - 60s - loss: 0.1045 - mae: 0.2339 - val_loss: 0.0322 - val_mae: 0.1258\\nEpoch 9/15\\n22371/22371 - 49s - loss: 0.1026 - mae: 0.2319 - val_loss: 0.0261 - val_mae: 0.1073\\nEpoch 10/15\\n22371/22371 - 49s - loss: 0.1026 - mae: 0.2311 - val_loss: 0.0259 - val_mae: 0.1055\\nEpoch 11/15\\n22371/22371 - 49s - loss: 0.1016 - mae: 0.2298 - val_loss: 0.0270 - val_mae: 0.1095\\nEpoch 12/15\\n22371/22371 - 49s - loss: 0.1003 - mae: 0.2283 - val_loss: 0.0281 - val_mae: 0.1151\\nEpoch 13/15\\n22371/22371 - 60s - loss: 0.1010 - mae: 0.2284 - val_loss: 0.0283 - val_mae: 0.1124\\nEpoch 14/15\\n22371/22371 - 56s - loss: 0.0995 - mae: 0.2270 - val_loss: 0.0218 - val_mae: 0.0968\\nEpoch 15/15\\n22371/22371 - 69s - loss: 0.0985 - mae: 0.2261 - val_loss: 0.0224 - val_mae: 0.0988\\n\\n\\nRMSE: 0.21629166347657777 MAE: 0.046145592754914616 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.954173\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.         0.98145318 0.93608507 0.94513782 0.91319197 0.93154762\\n 0.        ]\\n/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\\n  _warn_prf(average, modifier, msg_start, len(result))\\nRecall: \\t [0.         0.99346084 0.95495161 0.90567553 0.92370808 0.74835625\\n 0.        ]\\nF1 score: \\t [0.         0.9874205  0.94542423 0.92498597 0.91841992 0.82996354\\n 0.        ]\\nParams for Embeddings:  {'p': 1, 'q': 0.5}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   25.5s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_1_q_0.5.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 66s - loss: 0.1795 - mae: 0.3128 - val_loss: 0.0454 - val_mae: 0.1506\\nEpoch 2/15\\n22371/22371 - 56s - loss: 0.1281 - mae: 0.2623 - val_loss: 0.0394 - val_mae: 0.1313\\nEpoch 3/15\\n22371/22371 - 56s - loss: 0.1198 - mae: 0.2509 - val_loss: 0.0633 - val_mae: 0.1899\\nEpoch 4/15\\n22371/22371 - 52s - loss: 0.1145 - mae: 0.2435 - val_loss: 0.0368 - val_mae: 0.1316\\nEpoch 5/15\\n22371/22371 - 63s - loss: 0.1104 - mae: 0.2378 - val_loss: 0.0830 - val_mae: 0.1975\\nEpoch 6/15\\n22371/22371 - 63s - loss: 0.1080 - mae: 0.2343 - val_loss: 0.0258 - val_mae: 0.1038\\nEpoch 7/15\\n22371/22371 - 55s - loss: 0.1070 - mae: 0.2321 - val_loss: 0.0381 - val_mae: 0.1413\\nEpoch 8/15\\n22371/22371 - 56s - loss: 0.1057 - mae: 0.2301 - val_loss: 0.0315 - val_mae: 0.1201\\nEpoch 9/15\\n22371/22371 - 67s - loss: 0.1044 - mae: 0.2285 - val_loss: 0.0310 - val_mae: 0.1246\\nEpoch 10/15\\n22371/22371 - 63s - loss: 0.1039 - mae: 0.2274 - val_loss: 0.0381 - val_mae: 0.1367\\nEpoch 11/15\\n22371/22371 - 66s - loss: 0.1028 - mae: 0.2263 - val_loss: 0.0341 - val_mae: 0.1293\\nEpoch 12/15\\n22371/22371 - 54s - loss: 0.1023 - mae: 0.2255 - val_loss: 0.0334 - val_mae: 0.1394\\nEpoch 13/15\\n22371/22371 - 62s - loss: 0.1019 - mae: 0.2246 - val_loss: 0.0436 - val_mae: 0.1559\\nEpoch 14/15\\n22371/22371 - 62s - loss: 0.1015 - mae: 0.2242 - val_loss: 0.0404 - val_mae: 0.1454\\nEpoch 15/15\\n22371/22371 - 67s - loss: 0.1010 - mae: 0.2235 - val_loss: 0.0423 - val_mae: 0.1527\\n\\n\\nRMSE: 0.25913277213637537 MAE: 0.06707705177399116 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.932959\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.99833799 0.87554313 0.93537722 0.86828271 0.99741935]\\nRecall: \\t [0.92919421 0.98367067 0.92059333 0.85590903 0.46204423]\\nF1 score: \\t [0.96252595 0.92646268 0.92792639 0.86205147 0.63153595]\\nParams for Embeddings:  {'p': 1, 'q': 1}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.6s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_1_q_1.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 54s - loss: 0.1789 - mae: 0.3098 - val_loss: 0.0450 - val_mae: 0.1366\\nEpoch 2/15\\n22371/22371 - 53s - loss: 0.1239 - mae: 0.2572 - val_loss: 0.0327 - val_mae: 0.1144\\nEpoch 3/15\\n22371/22371 - 64s - loss: 0.1164 - mae: 0.2476 - val_loss: 0.0392 - val_mae: 0.1371\\nEpoch 4/15\\n22371/22371 - 62s - loss: 0.1117 - mae: 0.2416 - val_loss: 0.0371 - val_mae: 0.1382\\nEpoch 5/15\\n22371/22371 - 61s - loss: 0.1095 - mae: 0.2385 - val_loss: 0.0387 - val_mae: 0.1278\\nEpoch 6/15\\n22371/22371 - 53s - loss: 0.1076 - mae: 0.2361 - val_loss: 0.0452 - val_mae: 0.1525\\nEpoch 7/15\\n22371/22371 - 51s - loss: 0.1064 - mae: 0.2344 - val_loss: 0.0281 - val_mae: 0.1083\\nEpoch 8/15\\n22371/22371 - 51s - loss: 0.1048 - mae: 0.2322 - val_loss: 0.0229 - val_mae: 0.0919\\nEpoch 9/15\\n22371/22371 - 59s - loss: 0.1041 - mae: 0.2311 - val_loss: 0.0273 - val_mae: 0.1107\\nEpoch 10/15\\n22371/22371 - 49s - loss: 0.1036 - mae: 0.2303 - val_loss: 0.0273 - val_mae: 0.1131\\nEpoch 11/15\\n22371/22371 - 50s - loss: 0.1025 - mae: 0.2295 - val_loss: 0.0282 - val_mae: 0.1110\\nEpoch 12/15\\n22371/22371 - 62s - loss: 0.1023 - mae: 0.2290 - val_loss: 0.0286 - val_mae: 0.1104\\nEpoch 13/15\\n22371/22371 - 52s - loss: 0.1019 - mae: 0.2281 - val_loss: 0.0367 - val_mae: 0.1302\\nEpoch 14/15\\n22371/22371 - 60s - loss: 0.1018 - mae: 0.2279 - val_loss: 0.0279 - val_mae: 0.1088\\nEpoch 15/15\\n22371/22371 - 50s - loss: 0.1004 - mae: 0.2267 - val_loss: 0.0285 - val_mae: 0.1159\\n\\n\\nRMSE: 0.21110058774474005 MAE: 0.0442906763170816 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.955846\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.         0.98496083 0.94099215 0.94645092 0.88086384 0.99184149\\n 0.        ]\\n/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\\n  _warn_prf(average, modifier, msg_start, len(result))\\nRecall: \\t [0.         0.99008578 0.96876873 0.92693234 0.88656974 0.50866707\\n 0.        ]\\nF1 score: \\t [0.         0.98751666 0.95467844 0.93658995 0.88370758 0.67246148\\n 0.        ]\\nParams for Embeddings:  {'p': 1, 'q': 2}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   25.6s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_1_q_2.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 49s - loss: 0.1782 - mae: 0.3107 - val_loss: 0.0437 - val_mae: 0.1438\\nEpoch 2/15\\n22371/22371 - 49s - loss: 0.1260 - mae: 0.2585 - val_loss: 0.0515 - val_mae: 0.1693\\nEpoch 3/15\\n22371/22371 - 49s - loss: 0.1176 - mae: 0.2475 - val_loss: 0.0622 - val_mae: 0.1848\\nEpoch 4/15\\n22371/22371 - 50s - loss: 0.1136 - mae: 0.2417 - val_loss: 0.0353 - val_mae: 0.1277\\nEpoch 5/15\\n22371/22371 - 49s - loss: 0.1099 - mae: 0.2367 - val_loss: 0.0308 - val_mae: 0.1194\\nEpoch 6/15\\n22371/22371 - 49s - loss: 0.1077 - mae: 0.2331 - val_loss: 0.0869 - val_mae: 0.2035\\nEpoch 7/15\\n22371/22371 - 49s - loss: 0.1062 - mae: 0.2311 - val_loss: 0.0341 - val_mae: 0.1249\\nEpoch 8/15\\n22371/22371 - 60s - loss: 0.1048 - mae: 0.2291 - val_loss: 0.0302 - val_mae: 0.1174\\nEpoch 9/15\\n22371/22371 - 49s - loss: 0.1037 - mae: 0.2273 - val_loss: 0.0302 - val_mae: 0.1230\\nEpoch 10/15\\n22371/22371 - 60s - loss: 0.1023 - mae: 0.2255 - val_loss: 0.0267 - val_mae: 0.1038\\nEpoch 11/15\\n22371/22371 - 49s - loss: 0.1014 - mae: 0.2240 - val_loss: 0.0360 - val_mae: 0.1300\\nEpoch 12/15\\n22371/22371 - 49s - loss: 0.1007 - mae: 0.2231 - val_loss: 0.0392 - val_mae: 0.1276\\nEpoch 13/15\\n22371/22371 - 49s - loss: 0.0999 - mae: 0.2225 - val_loss: 0.0354 - val_mae: 0.1288\\nEpoch 14/15\\n22371/22371 - 49s - loss: 0.0995 - mae: 0.2214 - val_loss: 0.0318 - val_mae: 0.1227\\nEpoch 15/15\\n22371/22371 - 51s - loss: 0.0990 - mae: 0.2207 - val_loss: 0.0304 - val_mae: 0.1182\\n\\n\\nRMSE: 0.25673562790646587 MAE: 0.06585862627070868 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.934169\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.99524376 0.87882288 0.92595058 0.91293952 0.96942149]\\nRecall: \\t [0.92202222 0.95569385 0.9406246  0.93436016 0.70113568]\\nF1 score: \\t [0.9572348  0.91564782 0.93322991 0.92352565 0.81373569]\\nParams for Embeddings:  {'p': 2, 'q': 0.25}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   25.5s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_2_q_0.25.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 50s - loss: 0.1811 - mae: 0.3135 - val_loss: 0.0469 - val_mae: 0.1454\\nEpoch 2/15\\n22371/22371 - 49s - loss: 0.1253 - mae: 0.2584 - val_loss: 0.0354 - val_mae: 0.1227\\nEpoch 3/15\\n22371/22371 - 49s - loss: 0.1160 - mae: 0.2461 - val_loss: 0.0401 - val_mae: 0.1425\\nEpoch 4/15\\n22371/22371 - 49s - loss: 0.1107 - mae: 0.2387 - val_loss: 0.0306 - val_mae: 0.1130\\nEpoch 5/15\\n22371/22371 - 49s - loss: 0.1080 - mae: 0.2345 - val_loss: 0.0317 - val_mae: 0.1226\\nEpoch 6/15\\n22371/22371 - 49s - loss: 0.1064 - mae: 0.2321 - val_loss: 0.0462 - val_mae: 0.1675\\nEpoch 7/15\\n22371/22371 - 49s - loss: 0.1047 - mae: 0.2298 - val_loss: 0.0391 - val_mae: 0.1404\\nEpoch 8/15\\n22371/22371 - 50s - loss: 0.1034 - mae: 0.2276 - val_loss: 0.0306 - val_mae: 0.1170\\nEpoch 9/15\\n22371/22371 - 60s - loss: 0.1025 - mae: 0.2263 - val_loss: 0.0303 - val_mae: 0.1221\\nEpoch 10/15\\n22371/22371 - 49s - loss: 0.1020 - mae: 0.2252 - val_loss: 0.0306 - val_mae: 0.1141\\nEpoch 11/15\\n22371/22371 - 49s - loss: 0.1010 - mae: 0.2243 - val_loss: 0.0290 - val_mae: 0.1116\\nEpoch 12/15\\n22371/22371 - 49s - loss: 0.1003 - mae: 0.2233 - val_loss: 0.0262 - val_mae: 0.1087\\nEpoch 13/15\\n22371/22371 - 49s - loss: 0.1003 - mae: 0.2230 - val_loss: 0.0244 - val_mae: 0.1015\\nEpoch 14/15\\n22371/22371 - 59s - loss: 0.0992 - mae: 0.2217 - val_loss: 0.0280 - val_mae: 0.1182\\nEpoch 15/15\\n22371/22371 - 61s - loss: 0.0985 - mae: 0.2210 - val_loss: 0.0377 - val_mae: 0.1368\\n\\n\\nRMSE: 0.27130357575408487 MAE: 0.07196893924239393 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.928849\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.99733152 0.91506513 0.85990226 0.83867521 0.99824869]\\nRecall: \\t [0.96357756 0.9365383  0.93690572 0.79098892 0.34070532]\\nF1 score: \\t [0.98016403 0.9256772  0.89675397 0.81413438 0.50802139]\\nParams for Embeddings:  {'p': 2, 'q': 0.5}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   25.0s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_2_q_0.5.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 51s - loss: 0.1833 - mae: 0.3138 - val_loss: 0.0465 - val_mae: 0.1593\\nEpoch 2/15\\n22371/22371 - 59s - loss: 0.1257 - mae: 0.2605 - val_loss: 0.0368 - val_mae: 0.1329\\nEpoch 3/15\\n22371/22371 - 50s - loss: 0.1189 - mae: 0.2519 - val_loss: 0.0437 - val_mae: 0.1445\\nEpoch 4/15\\n22371/22371 - 60s - loss: 0.1151 - mae: 0.2470 - val_loss: 0.0374 - val_mae: 0.1379\\nEpoch 5/15\\n22371/22371 - 50s - loss: 0.1127 - mae: 0.2442 - val_loss: 0.0345 - val_mae: 0.1315\\nEpoch 6/15\\n22371/22371 - 60s - loss: 0.1112 - mae: 0.2425 - val_loss: 0.0317 - val_mae: 0.1215\\nEpoch 7/15\\n22371/22371 - 50s - loss: 0.1080 - mae: 0.2385 - val_loss: 0.0329 - val_mae: 0.1250\\nEpoch 8/15\\n22371/22371 - 49s - loss: 0.1070 - mae: 0.2372 - val_loss: 0.0366 - val_mae: 0.1319\\nEpoch 9/15\\n22371/22371 - 49s - loss: 0.1056 - mae: 0.2356 - val_loss: 0.0288 - val_mae: 0.1180\\nEpoch 10/15\\n22371/22371 - 50s - loss: 0.1043 - mae: 0.2341 - val_loss: 0.0253 - val_mae: 0.1068\\nEpoch 11/15\\n22371/22371 - 50s - loss: 0.1042 - mae: 0.2338 - val_loss: 0.0267 - val_mae: 0.1120\\nEpoch 12/15\\n22371/22371 - 50s - loss: 0.1032 - mae: 0.2325 - val_loss: 0.0275 - val_mae: 0.1136\\nEpoch 13/15\\n22371/22371 - 50s - loss: 0.1026 - mae: 0.2316 - val_loss: 0.0338 - val_mae: 0.1313\\nEpoch 14/15\\n22371/22371 - 51s - loss: 0.1020 - mae: 0.2309 - val_loss: 0.0238 - val_mae: 0.0993\\nEpoch 15/15\\n22371/22371 - 53s - loss: 0.1017 - mae: 0.2304 - val_loss: 0.0316 - val_mae: 0.1203\\n\\n\\nRMSE: 0.2620983733129163 MAE: 0.06856825910636673 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.931495\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.9655798  0.89987881 0.93030921 0.90362524 0.87363388]\\nRecall: \\t [0.96060095 0.93268435 0.90656299 0.87188715 0.76449492]\\nF1 score: \\t [0.96308394 0.91598794 0.91828261 0.88747253 0.81542875]\\nParams for Embeddings:  {'p': 2, 'q': 1}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   25.7s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_2_q_1.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 52s - loss: 0.1776 - mae: 0.3094 - val_loss: 0.0502 - val_mae: 0.1533\\nEpoch 2/15\\n22371/22371 - 51s - loss: 0.1233 - mae: 0.2577 - val_loss: 0.0426 - val_mae: 0.1452\\nEpoch 3/15\\n22371/22371 - 62s - loss: 0.1152 - mae: 0.2477 - val_loss: 0.0465 - val_mae: 0.1514\\nEpoch 4/15\\n22371/22371 - 51s - loss: 0.1106 - mae: 0.2416 - val_loss: 0.0397 - val_mae: 0.1388\\nEpoch 5/15\\n22371/22371 - 51s - loss: 0.1079 - mae: 0.2381 - val_loss: 0.0301 - val_mae: 0.1194\\nEpoch 6/15\\n22371/22371 - 51s - loss: 0.1057 - mae: 0.2353 - val_loss: 0.0279 - val_mae: 0.1141\\nEpoch 7/15\\n22371/22371 - 51s - loss: 0.1039 - mae: 0.2328 - val_loss: 0.0269 - val_mae: 0.1120\\nEpoch 8/15\\n22371/22371 - 62s - loss: 0.1022 - mae: 0.2310 - val_loss: 0.0279 - val_mae: 0.1133\\nEpoch 9/15\\n22371/22371 - 52s - loss: 0.1016 - mae: 0.2301 - val_loss: 0.0300 - val_mae: 0.1206\\nEpoch 10/15\\n22371/22371 - 51s - loss: 0.1010 - mae: 0.2291 - val_loss: 0.0258 - val_mae: 0.1036\\nEpoch 11/15\\n22371/22371 - 61s - loss: 0.1002 - mae: 0.2284 - val_loss: 0.0307 - val_mae: 0.1190\\nEpoch 12/15\\n22371/22371 - 52s - loss: 0.0997 - mae: 0.2270 - val_loss: 0.0255 - val_mae: 0.1061\\nEpoch 13/15\\n22371/22371 - 62s - loss: 0.0994 - mae: 0.2267 - val_loss: 0.0346 - val_mae: 0.1278\\nEpoch 14/15\\n22371/22371 - 52s - loss: 0.0988 - mae: 0.2259 - val_loss: 0.0299 - val_mae: 0.1124\\nEpoch 15/15\\n22371/22371 - 63s - loss: 0.0984 - mae: 0.2257 - val_loss: 0.0371 - val_mae: 0.1368\\n\\n\\nRMSE: 0.2426050823677292 MAE: 0.05760242957682445 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.943025\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.97959372 0.94744559 0.89856603 0.8432128  1.        ]\\nRecall: \\t [0.99348427 0.94079192 0.93479271 0.81905859 0.3341303 ]\\nF1 score: \\t [0.9864901  0.94410703 0.91632146 0.8309602  0.50089606]\\nParams for Embeddings:  {'p': 2, 'q': 2}  with embedding type:  node2vec\\nPreprocess transition probs...\\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.7s finished\\nLearning embedding vectors...\\nLearning embedding vectors done!\\nEMBEDDING VECTORS SAVED\\n./datasets/facebook_node2vec_p_2_q_2.npy\\nEMBEDDING VECTORS SHAPE: (4039, 128)\\nEmbedding method:  node2vec Binary operator: conv\\nEmbedded training set size: 1022640\\nEmbedded test set size: 109978\\nTrain test split summary: \\n Train X shape: (1022640, 2, 128, 1) Train y shape: (1022640,) \\n Test X shape: (109978, 2, 128, 1) Test y shape: (109978,)\\n\\n\\n\\n\\nEpoch 1/15\\n22371/22371 - 53s - loss: 0.1835 - mae: 0.3126 - val_loss: 0.0433 - val_mae: 0.1391\\nEpoch 2/15\\n22371/22371 - 52s - loss: 0.1305 - mae: 0.2578 - val_loss: 0.0533 - val_mae: 0.1668\\nEpoch 3/15\\n22371/22371 - 52s - loss: 0.1214 - mae: 0.2464 - val_loss: 0.0512 - val_mae: 0.1656\\nEpoch 4/15\\n22371/22371 - 52s - loss: 0.1167 - mae: 0.2397 - val_loss: 0.0631 - val_mae: 0.1994\\nEpoch 5/15\\n22371/22371 - 52s - loss: 0.1135 - mae: 0.2352 - val_loss: 0.0464 - val_mae: 0.1576\\nEpoch 6/15\\n22371/22371 - 51s - loss: 0.1115 - mae: 0.2325 - val_loss: 0.0476 - val_mae: 0.1602\\nEpoch 7/15\\n22371/22371 - 51s - loss: 0.1100 - mae: 0.2307 - val_loss: 0.0433 - val_mae: 0.1512\\nEpoch 8/15\\n22371/22371 - 52s - loss: 0.1091 - mae: 0.2291 - val_loss: 0.0381 - val_mae: 0.1316\\nEpoch 9/15\\n22371/22371 - 51s - loss: 0.1075 - mae: 0.2274 - val_loss: 0.0461 - val_mae: 0.1572\\nEpoch 10/15\\n22371/22371 - 51s - loss: 0.1072 - mae: 0.2264 - val_loss: 0.0424 - val_mae: 0.1477\\nEpoch 11/15\\n22371/22371 - 51s - loss: 0.1069 - mae: 0.2258 - val_loss: 0.0375 - val_mae: 0.1365\\nEpoch 12/15\\n22371/22371 - 52s - loss: 0.1058 - mae: 0.2246 - val_loss: 0.0400 - val_mae: 0.1455\\nEpoch 13/15\\n22371/22371 - 51s - loss: 0.1054 - mae: 0.2241 - val_loss: 0.0347 - val_mae: 0.1311\\nEpoch 14/15\\n22371/22371 - 62s - loss: 0.1050 - mae: 0.2234 - val_loss: 0.0439 - val_mae: 0.1496\\nEpoch 15/15\\n22371/22371 - 53s - loss: 0.1043 - mae: 0.2225 - val_loss: 0.0406 - val_mae: 0.1483\\n\\n\\nRMSE: 0.27630154041467053 MAE: 0.07390569022895488 \\nSummary: Train size: 1022640 Test size: 109978\\nAccuracy: 0.927313\\nPaths: \\t\\t [2 3 4 5 6]\\nPrecision: \\t [0.99542843 0.87093944 0.91709091 0.90947666 0.81953291 0.        ]\\nRecall: \\t [0.93392866 0.96363014 0.90592909 0.83302145 0.69216975 0.        ]\\nF1 score: \\t [0.96369837 0.91494321 0.91147583 0.86957175 0.75048607 0.        ]\\n/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\\n  _warn_prf(average, modifier, msg_start, len(result))\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_set = \"Params for Embeddings: .*'p': (?P<q>\\d+\\.\\d+|\\d+).*'q': (?P<p>\\d+\\.\\d+|\\d+)\"\n",
    "metrics = \".*MAE: (?P<mae>\\d+\\.\\d+|\\d+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.058229827783738565', '0.05545654585462547', '0.057656985942643076', '0.06007565149393515', '0.047936860099292586', '0.08535343432322828', '0.052792376657149614', '0.059784684209569186', '0.046145592754914616', '0.06707705177399116', '0.0442906763170816', '0.06585862627070868', '0.07196893924239393', '0.06856825910636673', '0.05760242957682445', '0.07390569022895488']\n",
      "16 16 16\n"
     ]
    }
   ],
   "source": [
    "maes_rmses= re.findall(metrics, data)\n",
    "maes = [metrics for metrics in maes_rmses]\n",
    "print(maes)\n",
    "q_ps= re.findall(param_set, data)\n",
    "ps = [params[0] for params in q_ps]\n",
    "qs = [params[1] for params in q_ps]\n",
    "print(len(qs), len(ps), len(maes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cm = plt.cm.get_cmap('RdBu')\n",
    "maes_np = np.asarray(maes, dtype=\"float32\")\n",
    "\n",
    "sc= plt.scatter(np.array(ps), np.array(qs), c=maes_np, cmap = cm)\n",
    "plt.colorbar(sc)\n",
    "plt.title(\"Max MAE: \"+ str(round(float(max(maes)), 2))+ \" Min MAE: \"+str(round(float(min(maes)), 2)))\n",
    "plt.xlabel(\"p\")\n",
    "plt.ylabel(\"q\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dict = {\"q\":[], \"p\":[], \"mae\":[]}\n",
    "for q,p,mae in zip(qs, ps, maes):\n",
    "    df_dict[\"q\"].append(q)\n",
    "    df_dict[\"p\"].append(p)\n",
    "    df_dict[\"mae\"].append(mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q</th>\n",
       "      <th>p</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.035134299587190165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.04102638709560094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.041981123497426755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0452908763570896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05400170943279565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05672952772372657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.05952099510811253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06496753896233792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.06526759897434033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0664132826565313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.06670424994089727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.06676789903435232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06802269544818054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06915019367509866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07453308843586899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07622433577624615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.07771554310862172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.07880667042499409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0798614268308207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.08137991234610559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.08296204695484552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.08400771063303569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0901089308770845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09019985815344887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10223862954409063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       q     p                   mae\n",
       "18  1.25  1.25  0.035134299587190165\n",
       "7      1  0.75   0.04102638709560094\n",
       "9      2  0.75  0.041981123497426755\n",
       "15   0.1  1.25    0.0452908763570896\n",
       "8   1.25  0.75   0.05400170943279565\n",
       "0    0.1   0.1   0.05672952772372657\n",
       "16  0.75  1.25   0.05952099510811253\n",
       "10   0.1     1   0.06496753896233792\n",
       "17     1  1.25   0.06526759897434033\n",
       "14     2     1    0.0664132826565313\n",
       "19     2  1.25   0.06670424994089727\n",
       "6   0.75  0.75   0.06676789903435232\n",
       "20   0.1     2   0.06802269544818054\n",
       "22     1     2   0.06915019367509866\n",
       "11  0.75     1   0.07453308843586899\n",
       "13  1.25     1   0.07622433577624615\n",
       "1   0.75   0.1   0.07771554310862172\n",
       "23  1.25     2   0.07880667042499409\n",
       "12     1     1    0.0798614268308207\n",
       "24     2     2   0.08137991234610559\n",
       "5    0.1  0.75   0.08296204695484552\n",
       "2      1   0.1   0.08400771063303569\n",
       "4      2   0.1    0.0901089308770845\n",
       "21  0.75     2   0.09019985815344887\n",
       "3   1.25   0.1   0.10223862954409063"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results_hyperparam_search.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
